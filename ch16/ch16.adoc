== B+Trees

|=== 
| Data Type    | B+Tree
| Write cost   | O(logN)
| Lookup cost  | O(logN), exact match, range queries
| Data type    | `sorted_map<span_t, uint64_t>`
| Maximum size | Unlimited
| Iteration    | Sorted iteration
|===

A B+Tree is an adaptation of a binary tree to the realities of the hierarchy of storage access speed. This is probably a very strange way to phrase things, I know.
Let's go back a step. I'm going to assume that you are familiar with https://en.wikipedia.org/wiki/Binary_search_tree[binary search trees] in this chapter. If you 
need a refresher, the Wikipedia page on the topic is a great introduction. Common implementation of binary search trees are AVL Trees and Red/Black Trees.

The key observation about binary search trees is that each time you visit a node, you cut the search space in half. That gives you the very desired property of 
`O(log~2~N)` insert and query times. There is a problem with such trees, however. You have to do a _lot_ of pointer chasing to get to the final result. If all your 
data is in main memory, you can usually ignore this cost (not really, but we'll pretend for a while). When your data is stored on disk, the situation is different.

Consider the code is <<naive-search-tree>>, which implements a binary search on top of a file. What would be the cost of running this code? The complexity is still
going to be `O(log~2~N)`, after all, but what would be the _cost_?

[source]
[[naive-search-tree]]
.A naive search tree implementation on top of FILE I/O
----
bool bst_find(FILE* f, char* key, uint64_t* val){
    node_t node;
    read_node(f, &node);
    int res = strcmp(key, node.key);
    if (res == 0){
        *val = node.value;
        return true;
    }
    int64_t pos = res < 0 ? node.left : node.right;
    if(pos < 0) return false; // not found
    fseek(f, pos, SEEK_SET);
    return bst_find(f,key,val);
}
----

In <<naive-search-tree>> we are doing one of the most expensive operations in terms of file I/O, small random reads. If the file in question holds 10,000 items
we'll need to perform _fourteen_ reads from the disk. Let's talk about 
https://www.freecodecamp.org/news/must-know-numbers-for-every-computer-engineer/[latency numbers every computer engineer must know]. This is a list of some really
interesting numbers in terms of latency. Doing a seek on a (good) HDD takes 3 milliseconds. That means that on a hard disk, the best speed for the `bst_find()` call
with just 10,000 items is 42 milliseconds. Even when running on SSD, you'll still have a cost of > 0.25 milliseconds running this function. That is a _lot_.

I'm using a very low number of items in the tree intentionally, to show how expensive binary search tree is. When the cost of accessing some parts of the tree are not
equal, the binary search tree costs are very high. This is were B+Trees are coming into play. Instead of having a node with just `left` and `right` pointers, we are going
to have much bigger nodes and an array pointers to child nodes. You can see how that looks like in <<btree>>.

[[btree]]
.A B+Tree has multiple pointers from each node to its children
image::btree.png[]

The idea with B+Trees is that we don't want to use `log~2~` for each node, which is the case where we have just two pointers. The typical number of pointers in a B+Tree
node is in the _hundreds_. That means that if we have 10,000 items, we don't need to do `log~2~(10,000)` but `log~256~(10,000)`. That means that instead of having 
to deal with 14 disk calls, we are going to need just 2. And if we raise the amount of items?
With 10 million items, a B+Tree with 256 pointers per node will request just 3 disk accesses. A binary search tree (just two pointers) will require 24 reads from the disk.

B+Trees are _far_ more efficient in this kind of environment. Indeed, B+Trees are on of _the_ most common persistent data structure you'll find. There is a _vast_ 
body of research on B+Trees and they have been in use for over half a century.

.B+Trees and memory hierarchies
****
I mentioned in the beginning of this chapter that B+Trees are meant to adapt a binary search tree to the realities of memory hierarchies. In any modern computer, you'll
find that you have roughly the following hierarchy of memory access speed:

* Registers
* L1 Cache
* L2-L4 Cache
* Main memory
* Disk

I'll admit that this is _still_ a simplified model. If you are running on NUMA nodes (non uniform memory access, common in multi socket machines), for example, you have
local memory and remote memory as well. Disk is often divided into multiple layers with different access speeds as well. 

In general, regardless of how you store the data, there are usually huge difference in cost vs. size vs. speed between layers. It takes a nanosecond to read a value from
the L1 cache, but 100 nanoseconds to read the same value from RAM. It takes 16 micro seconds to read a value from SSD, and far longer from an HDD. In general, the bigger
the storage, you can assume that the more expensive it is. And the economic realities means that you are going to have to deal with memory hierarchies. 

You _can_ get machines with many TB of RAM, mind you. That still doesn't mean that you can ignore the memory hierarchy. I looked at AWS and found `u-24tb1.metal`, which is
a bare metal server with 24 TB of RAM. This has 8 separate NUMA nodes to take into account. It has 448 cores running `Intel Xeon 8280L`. These chips has
1.75MB of L1 cache, 28MB L2 cache and 38.5 MB L3 cache. Even in this case, you have to juggle the memory hierarchy and the different latencies between them. 

B+Tree works in pages which allows us to take advantage of locality of reference. That was initially meant for reducing disk access, but it turns out that they work great
for reducing costs in any memory hierarchy. A good discussion on the topic is also on the https://queue.acm.org/detail.cfm?id=1814327[You Are Doing It Wrong] paper. 
****

This is meant to be a practical book, not a theoretical discussion on implementation decisions. For that, read the 
https://w6113.github.io/files/papers/btreesurvey-graefe.pdf[Modern B+Tree Techniques] paper does a great job covering the full details of the history of design and 
implementation of B+Trees.
I'm going to outline my approach for implementing the B+Tree for Gavran and explain what I'm doing, without going too deeply into alternatives or divergent design.

We previously built an extendible hash table and we simplified our model by limiting the data structure to be `map<uint64_t, uint64_t>`. In the same manner, we are
going to implement a B+Tree that would behave like a `sorted_map<span_t, uint64_t>`. In other words, we're going to have the API shown in <<btree_api>>.

[source]
[[btree_api]]
.`gavran/db.h` - API for working with B+Trees in Gavran
----
include::../include/gavran/db.h[tags=btree_api]
----

You can see that the API is very similar to the one we have built for hash tables. For now, I'm omitting the API for iterating over the B+Tree, we'll discuss this 
later on in this chapter. Because B+Trees are ordered, this means that the iteration API is more complex, for now I want to focus on the Read / Write / Delete operations.
Let's look at the actual implementation and see how that works.

=== Creating a B+Tree

.B+Trees can be complex beasts
****
In terms of line of code, the B+Tree implementation in Gavran is about 1.26 times larger than the Extendible Hash Table or the Containers we previous looked at. 
In terms of complexity, however, I find the B+Tree code to be far more complex.

Conceptually, the idea of a B+Tree is fairly simple and obvious, but the implementation tends to be quite tricky. One of the most common issues is that any modification
to the tree may have repercussions higher up the tree. When dealing with variable length values, that can make the code more complex and expose several edge cases that
you have to handle. 

To manage that complexity, we have the `btree.debug.c` file, which has API to dump a textual representation of the tree that you can inspect by hand. That can be 
quite important to understand how the B+Tree is mutated by your changes. It can be invaluable for understanding and debugging issues. When writing Voron, I actually had
the engine output HTML trees that would allow inspection of the B+Tree structure of the data. 
****

A B+Tree is composed of two types of pages, we have a _branch_ page, which points to other pages, and we have _leaf_ pages, which hold the actual value. In both cases,
they are structured in the exact same manner, since the only value we allow in our trees are `uint64_t` and that is the value what we need to store in the branch pages 
to point to the leaf pages. As such, the process of creating a B+Tree is simple, as you can see in <<btree_create>>.

[source]
[[btree_create]]
.`btree.c` - Creating a new B+Tree with a single leaf page 
-----
include::./code/btree.c[tags=btree_create]
-----

There isn't much going on in `btree_create()`, is there? We simply allocate a page and setup its metadata. You can see that like the container pages, we have the notion
of `floor` and `ceiling` values for the page. Indeed, much of the same techniques are reused between the two data structures. 

=== Writing to the a B+Tree

Writing a value to a B+Tree is done using the `btree_set()` method. It accepts a `btree_val_t` which has the key and the `uint64_t` value and may optionally return the
old value of the key. In the container, we were able to simply able to append the new value to the page wherever we had room, but in the case of the tree, we cannot do
that. One of the key aspects of a B+Tree is that it is sorted, after all.

[IMPORTANT]
.Keys in the B+Tree
====
The B+Tree we will use is going to use binary data as keys. The key is of type `span_t`, so the key _data_ is just any arbitrary memory of some size. We are going to limit
the key size to 512 bytes. It simplify our lives and there is rarely the need for larger keys. 

If the keys are arbitrary data, how can we sort on them? We are going to use the `memcmp()` function as the sorting function. It means that the keys you'll generate should
be sortable in lexical order using their raw binary value. It would be simple to provide a comparison function to the B+Tree to allow for more complex comparisons, but 
I find that it is usually only make things more complex to the implementor and the user alike. 

The fact that the keys are opaque bytes has some interesting implications on sorting when using numbers, for examples. We'll address this in detail later in this chapter.

We ensure that all our keys fit the required criteria using the code in <<btree_validate_key>>. 

[source]
[[btree_validate_key]]
.`btree.c` - Validating that the provided key is valid (1 .. 512 in size and not pointing to `NULL`).
-----
include::./code/btree.c[tags=btree_validate_key]
-----
====

The structure of a page in the a B+Tree is shown in <<btree_page>>, you can see the metadata on the left, with the ceiling and floor markers. Then we have the values.
The bottom of the page is also used to store the indexes of the values in the page, and the positions of the _values_ in the page doesn't matter. It is stored on a first
come, first served basis. 

The order of the _positions_ on the page, on the other hand, matters greatly. If you'll look at the bottom of the page in <<btree_page>> you can see that the positions
themselves are sorted, using the key.

[[btree_page]]
.The structure of a single B+Tree page
image::btree_page.png[]

In other words, when we need to insert a new item into a B+Tree page, we'll append the actual value to the top of the `ceiling`, lowering it along the way.
This is just like we do with the container pages.
But instead of just recording the index of the value in an arbitrary location, we'll sort the `positions` array at the bottom of the page according to the sort order of 
the key.

The idea is that this means that we'll have to move far less memory, which is more efficient in general and will also play really well with our WAL format. As a reminder,
we use a diff based WAL format, which means that the less changes we can make to a page, the less we have to write to disk.

In <<btree_page>> you can see that the leftmost entry in the top page (which is a branch page) is the empty symbol: `∅`. The leftmost key in branch pages can be empty, and
has the meaning of "smaller than anything on my right". This approach allows us to add smaller value than the current minimum on the page without having to update the 
entire tree with the new smallest value.

==== Searching a key in a page

Let's look first at what is probably _the_ most important piece of code for our B+Tree, the sort routine shown in <<btree_search_pos_in_page>>.

[source]
[[btree_search_pos_in_page]]
.`btree.c` - Searching for the right position of a key inside a B+Tree page
-----
include::./code/btree.c[tags=btree_search_pos_in_page]
-----

The code in <<btree_search_pos_in_page>> is a simple binary search. It turns out that most binary search implementation have a bad bug in them, which you can read in 
https://ai.googleblog.com/2006/06/extra-extra-read-all-about-it-nearly.html[Nearly All Binary Searches and Mergesorts are Broken]. 
Our code has the fix for this, but it wouldn't matter anyway for our purposes, we are dealing with much smaller range of values. 

We are doing a binary search through the page's entries. Using the `positions` array to get to the stored key and compare it to the one what was supplied to the function.
We start at the middle of the `positions` array and we split the remaining range in half each time we find a greater or lesser value. If we find an exact match, we can 
return the position immediately. 

If we _don't_ have a match, we have to return where the value _should_ go. If the `last_match` we had was smaller than the current value, then the value needs to be on the 
_following_ position, so we increment it. Finally, we can return the bitwise complement to the position, to indicate a missing value. The `\~` operator allows us to distinguish
between a value that was found in the page or not. But why not return `-1` or something similar?

We are going to use `btree_search_pos_in_page()` to tell us where we should be _placing_ a value in the page, not just where it _is_. Using `\~` allows us to do the work of
searching in the page just once. Why does this matter? We'll be calling to `btree_search_pos_in_page()`  a _lot_. 
If you'll run the B+Tree code under a profiler, you are very likely to find this function in your hot spots. Any optimization in the search is going to have a big impact on
our B+Tree performance.

[TIP]
.Empty keys behavior for `btree_search_pos_in_page()`
====
The leftmost key (marked as `∅` in the <<btree_page>>) in the leftmost branch page on each level is always empty and is treated as smaller than anything else. We handle this 
scenario explicitly in `btree_search_pos_in_page()`, as you can see in <<btree_search_pos_in_page>>. An empty key can only appear as the leftmost key in a branch page.

This is useful when we are adding items that are smaller than the smallest key in the tree. We can simply walk to the leftmost entry along the tree until we reach the
location we'll place the new key. If we didn't use the empty key, we'll need to update the leftmost entry of the tree each time we added the minimum value. On large
trees, that means that we have to update the entire hierarchy. By using an empty key, we can handle that implicitly. 
====

==== Finding _where_ to make the write

The `btree_set()` function is shown in <<btree_set>> and isn't really that interesting. All it does is find the appropriate page to set the value on and then set the value
on that page. 

[source]
[[btree_set]]
.`btree.c` - Setting a value in the B+Tree
-----
include::./code/btree.c[tags=btree_set]
-----

The work in `btree_set()` can be divided into finding the right page to set the value using `btree_get_leaf_page_for()` and actually setting the value in `btree_set_in_page()`.
Both of them are far more complex under the covers than you might expect. Let's start with the first step, finding the leaf page. Why do we even need that?

A B+Tree is composed of branches and leaves. The actual values for the keys we store in the B+Tree are held only on the leaves. On the branches, we simply hold pointers to the
leave pages. So in order to actually set the key and value on the B+Tree, we find need to find the appropriate leaf page to add the value to. Let's look at 
<<btree_get_leaf_page_for>> to see how this is done.

[source]
[[btree_get_leaf_page_for]]
.`btree.c` - Finding the appropriate leaf page for a given key
-----
include::./code/btree.c[tags=btree_get_leaf_page_for]
-----

Starting from the root page, we search for the given key using `btree_search_pos_in_page()`. If we are on a branch page, we use the position from the search to go down the tree
toward the appropriate leaf page. If you'll look back in <<btree_page>> you'll see that the branch page don't hold all the keys of the leaf pages. Instead, it hold the a key
that is less than or equal to the first key in the page that it points to. That means that when scanning branch pages, we'll very often see searches that haven't got an exact
match. For that reason, we have to do a fixup to find the right location to do the next search.

We first use bitwise complement to invert the behavior of `btree_search_pos_in_page()` when an exact match isn't found and we decrement the value if the last match was too
big for us. The idea is that the keys in the branch page represent a _range_ of values. Looking at the tree in <<btree_page>>, we have the `∅ .. 2` as the first range, `3 .. 7`
as the second, `8 .. 11` as the third and the final range is `12 .. ∞` (where `∞` is infinity, so any larger value). 
We determine the range as the equals or greater than that the key entry in the branch and smaller than the _next_ key in the branch page. 

Once we found the next position to go through, we get the child page that is pointed to and continue the process until we get to a leaf page. Because of the size of the branch
pages, the number of branch pages is usually very small. Even if you have a billion items in the B+Tree, you'll only need three steps to get to the leaf page. Once we go to the
leaf, we run `btree_search_pos_in_page()` _again_. This time, we need to find the position of the key _inside_ the leaf. 

If the key doesn't exists, `btree_search_pos_in_page()` will set the `position` to a negative value. A bitwise complement to where the value _should_ go. That is very useful in
both searches and when we need to insert a new value to the leaf page.
Right now, we only have a single page in the B+Tree, the root page we created in `btree_create()`. When we create the B+Tree, we create a single leaf page, so as it currently 
stands, we'll not get to the `while` loop and only do a search directly inside the leaf page.

We looked into how `btree_get_leaf_page_for()` find the right page to work with, but there is another thing that is is responsible for. The current working stack. In the code
you can see that inside the transaction's state, we have the `tmp_stack` that we use to track where we are in the B+Tree. 

==== Traversing paths in the B+Tree

When we search inside the B+Tree, we start at the root and go downward toward the leaf page that contains the actual values that we are interested in. If we are interested in
simply searching to the value, we don't care about the path we walked through to get there. But when we want to _modify_ the data, the path to the leaf page is very important.
If we need to split the page (or merge it), we need to know what the _parent_ page is.

If you'll notice, the `tree_page_t` struct hold no information about the parent page, so we can't go up the tree, only down. The stack is used to allow us to climb up back the
tree. In the _vast_ majority of the cases, the depth of the tree (and the size of the stack) is going to be very shallow. I would be shocked to see if hit double digits. 
In fact, we can compute that. If we can put merely 10 entries per page, we'll have a tree depth of 9 with a billion items in the tree. Note that usually an 8KB page will contain
hundreds of entries, so the depth of the tree (and the size of the stack) is far less. 

The stack we use to store the traversal path in the B+Tree is about as simple as you can get. The API is shown in <<btree_stack_t>>.

[source]
[[btree_stack_t]]
.`gavran/db.h` and `gavran/internal.h` - API for using the B+Trees stacks to manage the path traversal
----
include::../include/gavran/db.h[tags=btree_stack_t]

include::../include/gavran/internal.h[tags=btree_stack_api]
----

The stack is basically just two parallel arrays that are used to store the page number and the position within this page. I used a struct of array instead of array of struct
to get better density of data and avoid alignment issues. You can see the `btree_stack_push()` and `btree_stack_pop()` implementation in <<btree_stack>>.

[source]
[[btree_stack]]
.`btree.stack.c` - Pushing and popping values from the B+Tree stack
-----
include::./code/btree.stack.c[tags=btree_stack]
-----

As I mentioned, the depth of the stack is _very_ unlikely to grow very big. And the _push_ and _pop_ operations are quite cheap. We're going to be using the stack each and
every time we search the B+Tree, which means that making this efficient is a priority. The cost of the stack usage is negligible, but the cost of memory allocation and 
de-allocation is very high. 

To handle these costs, we aren't going to allocate and free the stack every time that we traverse the B+Tree. Instead, we have added a field to the `txn_state_t` structure
named `tmp_stack`. This is initialized by the first B+Tree search we run (using `btree_increase_size()`) and then reused each time. We'll cleanup the allocated `tmp_stack`
when we call `txn_close()` on the transaction. The remaining functions for the stack implementation are shown in <<btree_stack_utils>>.

[source]
[[btree_stack_utils]]
.`btree.stack.c` - Peeking, freeing and clearing the B+Tree stack
-----
include::./code/btree.stack.c[tags=btree_stack_utils]
-----

The main reason we need this stack is to store the traversal path in the tree, but why is this required? This is useful when we need to modify the structure of the tree 
itself, for example, when a page grows too large and we need to split it. Let's look into how we manage the space inside a B+Tree page.

==== Space allocation and usage in a B+Tree page. 

In `btree_set()` there are two main operations. The first, which we looked at, is finding the right page to work with using `btree_get_leaf_page_for()`. The second part
is writing the actual entry to the page in `btree_set_in_page()`, which we'll look at now. 

The structure of a B+Tree page in Gavran is very similar to the container pages we looked at in the previous chapter. We write the data to the page from the `ceiling` and 
write the position of the entry to the `positions` array from the `floor`. Unlike container pages, however, we don't use arbitrary order but require that the items in the
`positions` array will be sorted. Note that there is no such requirement for the entries' data. That allows us to save on a lot of memory moves when we are adding a new
item to a B+Tree page, since we only have to shift a (much smaller) amount of `uint16_t` offsets. 

The bulk of the work of writing an entry to a page isn't actually done by `btree_set_in_page()`. Instead, this function is charged with making sure that there is enough 
space in the page to accommodate the new entry. Let's look at the code <<btree_set_in_page>> and then we'll discuss what is going on in detail.

[source]
[[btree_set_in_page]]
.`btree.c` - Setting an entry on the page, updating in place if possible
-----
include::./code/btree.c[tags=btree_set_in_page]
-----

The code in <<btree_set_in_page>> first check if we are inserting a new value or updating an existing one. This is done using the `set\->position` value, which was set by
calling the `btree_search_pos_in_page()` call in `btree_get_leaf_page_for()`. If we are updating an existing value, we'll try to update it in place. If we are successful,
we are done. This is simple, because we just have to update the data in the page and not change its structure.

But if we can't do an in place update, or if we are inserting a new entry, we will need to append the new entry to the page. This is more complex, because we have to deal
with quite a few edge cases. Let's look at the in place update first, shown on <<btree_try_update_in_place>>.

[source]
[[btree_try_update_in_place]]
.`btree.c` - Trying to do an in place update when updating the value of an existing entry
-----
include::./code/btree.c[tags=btree_try_update_in_place]
-----

The code in `btree_try_update_in_place()` get the existing entry and see if the size of the entry already on the page can fit the new value. If so, we write the new value
at the end of the key and then zero the rest of the memory (if the new value is smaller than the old one). 
If there isn't enough space, we'll zero the entire entry and try to append the entry to the page as a new item (but keeping the same position). This is shown in 
<<btree_append_to_page>>. What is interesting is that in `btree_append_to_page()` we aren't actually doing much appending, what the function is doing is make sure that there
is enough space _to_ append the entry.

[source]
[[btree_append_to_page]]
.`btree.c` - Write a new entry to the B+Tree page, making sure that we have enough space to do so
-----
include::./code/btree.c[tags=btree_append_to_page]
-----

In `btree_append_to_page()` we start by checking how much available space we have (the distance between the `ceiling` and the `floor`). We write entries to the B+Tree page
from the `ceiling` down, toward the `floor`. This is identical to how we did things in the container pages in the previous chapter. There are two scenarios that may occur if
the space between the `ceiling` and `floor` is too small. It is possible that there is enough free space in the page, but it is not available on a continuous basis. We handle
this scenario using the `bree_defrag()` function. The other scenario is that the page is full and there is no more space for it. 
In that case, we'll need to split the page. But before we can split the page, there is some bookkeeping that we have to deal with.

When we are updating an existing entry and we get to the `btree_append_to_page()` function, we know that the entry has already been zeroed on the page, but there is still the
allocate `position` entry for the entry. Before we can split the page, we need to remove the remains of the entry and only then we can split the page.
Before getting to the details of page splits, let's look at how we are defragging a B+Tree page.

==== Defragging a B+Tree page to recover space

In the previous chapter, we also implemented de-fragmentation on the container pages. The implementation for B+Tree pages is very similar, but has some important differences.
Unlike container pages, we aren't forced to keep the `position` in the same location for all time. We will routinely move the actual `position` of an entry in a page around.
On the other hand, on a B+Tree page, the _reason_ we move an entry around is that we need to maintain the sorting order. Defragging a B+Tree page means that we are already
working on a sorted entry, so we just need to reshuffle the entries, not the positions. You can see what we do in <<btree_defrag>>.

[source]
[[btree_defrag]]
.`btree.c` - Recovering from internal fragmentation in the B+Tree
-----
include::./code/btree.c[tags=btree_defrag]
-----

We allocate a temporary buffer to hold a copy of the page data and then we zero the page's data (but we are skipping the `positions` array at the bottom of the page). Then 
we can simply run through the entires and copy the actual entry data from the temporary buffer back to the page, layering them one at a time on top of the `ceiling` and updating
the offset of the `position` in the page. This is pretty simple code and it ends up with us being in an optimal shape and without any wasted space. 

==== Page splits in the B+Tree

The real complexity we have in a B+Tree is all around page splits and page merges. A page split occurs when we try to write an entry that should go to a page that is full. At 
this point, we have to split the page into two. That means that we have to take the following actions:

* Allocate a new page.
* Divide the entries between the current page and the new one.
* Insert a reference to the newly allocated page to the _parent_ page.

It is the last action that is causing the complexity. When we insert a new item to the parent page, it is possible that the _parent_ will be full. That requires us that we'll
split the parent page as well. And maybe the _grandparent_ as well, etc. This means that we have to be careful about working with the B+Tree because any modification can change
the shape of the tree. In practice, it doesn't happen very often (once every few hundreds inserts, usually), but it is the cause of significant complexity.

If you'll look at `btree_append_to_page()` you'll see that after we call to `btree_split_page()` we also call to `btree_search_pos_in_page()`. This is done because we changed
the entries in the page, so we need to find the new position for the entry.

You can see the start of the splitting process in <<btree_split_page>>. This is just the start because the process is somewhat involved, so I've split it into multiple 
functions.

[source]
[[btree_split_page]]
.`btree.c` - Splitting a B+Tree page into two separate pages and re-balancing the entries
-----
include::./code/btree.c[tags=btree_split_page]
-----

The `btree_split_page()` is called when the current page is out of space. That can be the first (leaf) page in the tree or any other page in the tree. The first thing we
check is if we go to the top of the tree and we need to create a new root page. This is the first time that we actually make use of the traversal path stack in our code. 
If we need to split a page and it is at the top of the tree, we'll introduce a new root page using `btree_create_root_page()`. We'll look into that function in a bit, for
now, let's focus on what is actually happening in on the code in <<btree_split_page>>.

.The cost of splitting a page
****
One of the interesting properties of B+Tree is that the patterns of writes can have a significant impact on the performance of the system. When we deal with the
Extendible Hash Table, there was no real difference with how you structured your keys or in what manners you read data from the hash table. With B+Tree, the situation is 
very different.

When we insert data in a sequential manner, we are able to fill up a page completely before we need to split it. That means that the internal fragmentation of the pages is
low and the _depth_ of the tree is optimal. If we write the same data, but in a random fashion, then we are likely to have to split the pages much earlier and leave unused
space in the pages.

The extra page splits will cause us to have a greater tree depth, and that is is leading cause of additional costs in a B+Tree. The B+Tree implementation in Gavran 
is going to try to reduce the number of page splits by as much as possible. One of the way we do that is to avoid storing any actual data in the B+tree, we only store 
a `uint64_t` value. Voron's B+Tree, on the other hand, may contain arbitrary sized data, which complicates the implementation significantly. 

The _user_ of the B+Tree is also encouraged to take the access patterns into account. Storing the data in sorted order is _much_ better all around.
****

The `btree_split_page()` function make a distinction between three separate scenarios for a page split:

* The page is split because of a new entry whose key is _higher_ than the last entry in the page. This will commonly happen when you are using ascending keys, such as
  incrementing numeric values, etc.
* The page is split because of an entry whose key is _lower_ than the first entry in the page. This happens when you are writing in descending order. Usually because
  you are writing data from another source which is already sorted. There are actually very few scenario where this will happen, though. 
* The page is split because of an entry whose key falls somewhere in the _middle_ of the page.

The reason we have to deal with all three scenarios is to get the optimal behavior. In the first two cases, we don't _need_ to split the page. Instead, we can simply
allocate a new (empty) page in the tree, wire it up to the parent page and call it a day. The new write will go to the new page and we get the optimal density of the
data. 
If we have a write to the middle of the page, we have to actually split the page _and_ split the data, leading to potentially wasted space inside the pages. You can 
see the three options in the <<btree_split_page>>. 

We use the `ref.key` to hold the key that will be inserted to the parent page and will contain the newly allocated page. That key will be used to find the entries
in the new page. 

[IMPORTANT]
.You can make a _single_ change to the tree
====
An interesting implication of the fact that an insert to a page can cause a page split is that we have a hard time to do multiple operations on the page at the same
time. For example, if we wanted to modify two keys in the parent page, we might run into a case where the first key would cause a page split in the parent page, which
will cause the _next_ key to go to another page.

We _could_ handle it, but it is easier to accept a limit of a single modification to the parent page and avoid that complexity.
====

If `seq_write_up` is true, we are looking and a sequential write. In this case, we set the new page's initial key to be the new key that we are now inserting to the 
tree. We also change what page the entry will be written to. If we have a sequential write, we're changing the destination page to the newly allocated page.
The new page is currently empty, but we'll fill it with the new value as soon as we return from the `btree_split_page()`. 

On the other hand, if `seq_write_down` is true, that means that we have a descending write. A write that is less than the first item in the page represents an interesting
problem for us. The issue is that we'll need to place the new page _before_ the current page. That is easy enough to do in most cases, except if the current page
is the leftmost page (smallest value) in the parent page. Why is that a problem?

If you'll look at <<btree>>, you'll see that the leftmost key in the branch page is an empty value, which we marked it as `∅`. If the current page is already using the key
that means "smaller than anything", how can we write a value to the page that will mean smaller still?
We could update _both_ pages keys, but that has its own problem. Each write to the page may split it, so if we make multiple writes to the page we'll need to handle the
possible split for each write. That is complex to do and opens us up to various edge cases.

Instead, we go the other way around. We _move_ all the entries from the current page to the new one, and reset the current page. We then insert the _new_ page to the tree
using the smallest value in that page (or its children, done using `btree_get_leftmost_key()`). The actual write that will happen after the call returns will happen in 
the current page, which is now empty and ready to accept more writes that are smaller still. 
In this case, even though we moved the whole page, we are still in a very good place, in terms of information density. We didn't have to actually split the entires, just
move where they reside. 

To find the smallest key to write to the parent page, we call to `btree_get_leftmost_key()`. Why do we need to do that? Because the current page we move may be a branch
page with the leftmost key is empty (`∅`). In order to find what is the _actual_ smallest key for a page, we may need to go down the leftmost path until we reach a leaf page.
You can see how this is done in <<btree_get_leftmost_key>>.

[source]
[[btree_get_leftmost_key]]
.`btree.c` - Getting the smallest key from a page (or its children)
-----
include::./code/btree.c[tags=btree_get_leftmost_key]
-----

Now that we understand how we deal with writes that are greater than the entire page or smaller than the page, let's talk about writes to the middle of the page. This is the
case where we are actually splitting the page and dividing the entires between the two parts. This is done in the `btree_split_page_in_half()` function, shown in 
<<btree_split_page_in_half>>.

[source]
[[btree_split_page_in_half]]
.`btree.c` - Moving half the entires in a page to the newly allocate page.
-----
include::./code/btree.c[tags=btree_split_page_in_half]
-----

We are doing a few interesting things in <<btree_split_page_in_half>>. First, we take all the entires in the 2nd half of the current page and move them to the new page.
The new page will always get the larger half of the entries. The first entry in the new page will be the reference key for the new page to the parent page. You can see
how we determine that in `btree_split_page_in_half()` by setting the `ref\->key`'s value to the first entry's key that we process.

One we are done copying half the entries to the new page, we'll zero out the entries we copied on the original page. We end up with two pages, each with half of the 
entries of the original page. The last thing tha we need to handle on this function is deciding what page we'll write the value to. This is why we pass the `set` to
the function.

Because we split the page in half, the `set\->key` may belong to either page. This function will check whatever we should be writing it to the current page or whatever
it belongs in the newly allocated page. If the key on `set` belongs to the newly allocated page, we'll set it as the destination for the next write in the set operation.
This is similar to what we do in `btree_split_page()` when we have a sequential write and just allocate a new page for the new data.

[TIP]
.We aren't dealing with comparing against the empty key when splitting the page
====
In `btree_search_pos_in_page()` we had to deal explicitly with the empty key, but in `btree_split_page_in_half()`, we are calling `memcmp()` without special
casing for the empty key. Why is that?

In `btree_split_page_in_half()` we are comparing a key that is _not_ the leftmost entry. This is because we compare against the entry at the half way mark from
the original page, and we know that an empty key cannot reside there.
====

The last portion of splitting a page is calling to `btree_append_to_parent()`, shown in <<btree_append_to_parent>>. This is where we wire the new page to the tree using
the appropriate key. 

[source]
[[btree_append_to_parent]]
.`btree.c` - Adding the new page to the tree by writing the new key to the parent page.
-----
include::./code/btree.c[tags=btree_append_to_parent]
-----

We use the stack to get the parent's page number and prepare the page for modifications. We then search the parent page using `btree_search_pos_in_page()` to find the 
appropriate location for the new entry. We conclude the process by calling to `btree_set_in_page()` to do the actual write. 

The last part is important, because if you'll recall, `btree_append_to_parent()` is called from `btree_split_page()` which is called in turn from `btree_append_to_page()`
which is called from `btree_set_in_page()`. In other words, we have now entered a recursive call. This time, we aren't operating on the leaf page but on its parent branch
page. 

An addition to the page may trigger another page split, which will go upward in the tree (using the stack) all the way to the root. Once we get to the root, we'll need to
allocate a new page for the root. This is shown in <<btree_create_root_page>>.

[source]
[[btree_create_root_page]]
.`btree.c` - Creating a new root page for the tree.
-----
include::./code/btree.c[tags=btree_create_root_page]
-----

The new root page is always a branch page which has an empty leftmost key pointing to the current root page. When doing similar things with the Extendible Hash Table, we 
had to change the `hash_id` of the table whenever we grew the directory. That is something that I would like to avoid doing for B+Tree, so you'll note that I'm allocating
a new page in `btree_create_root_page()`, but that isn't used for the _root_ of the tree. Instead, I'm moving the old root page to the new page and setting the _original_
page as the root page again. In this manner, the `tree_id` of the B+Tree is constant and will never change. 
The final act of the `btree_create_root_page()` function is to register the new root tree in the stack, so we'll be able to later use the new root page as the parent page.

[NOTE]
.The empty (`∅`) key marker
====
The root page is always created with a single entry using an empty key. This is used to refer to "smaller than anything" value. At each level, the leftmost branch page will
have its leftmost key set to an empty key. 

Other branch pages may have a leftmost key with an actual value or have an empty key. That depends on the exact series of operations that were applied to the tree. It doesn't
matter much if the leftmost key on anything but the leftmost branch page has an empty key. 
====

The final piece of adding an entry to page is `btree_insert_to_page()`, shown on <<btree_insert_to_page>>. 

[source]
[[btree_insert_to_page]]
.`btree.c` - Prepare the page for a new inserted entry.
-----
include::./code/btree.c[tags=btree_insert_to_page]
-----

The `btree_insert_to_page()` function doesn't handle the actual insertion. Instead, it prepares the space in the page for the insertion and returns the location to write the
new entry. Mostly it is about updating the page metadata, but note the different behavior of this function if the `position` specified is positive or negative.

If we are passed a positive `position`, we are _updating_ an existing entry, so we don't need to touch the `positions` array. But if we are passed a negative position we know
that we have to allocate space for the new entry's `position`. We call `memmove()` to do the heavy lifting of creating the appropriate space in the `positions` array to fit 
the new entry's offset in the page. 

As you can see, adding an item to the B+Tree isn't a trivial operation. Not so much because of what happens during normal operations but because of the number of edge cases
that we have to deal with. The fact that we ensured that the maximum size of an entry can be up to `KeyLenSize(2) + KeySize(512) + ValSize(10) = MaxEntry(524)` actually
simplify a lot of things. Given that the size of a page is 8KB, we don't need to worry about not being able to double split (splitting the page once, and still not having
enough room for the value we want to insert) or have to balance the size of entries along with their number, etc.

Now that we know how we set values into the B+Tree, let's see how we can _read_ data from the tree.

=== Reading from the B+Tree

We actually have most of the functionality for reading already explored. Let's look at how `btree_get()` is implemented in <<btree_get>>.

[source]
[[btree_get]]
.`btree.c` - Getting a value from the tree by key
-----
include::./code/btree.c[tags=btree_get]
-----

We already saw how `btree_get_leaf_page_for()` works in <<btree_get_leaf_page_for>>. It searches through the tree to find the appropriate leaf page for the key we are searching
for. If the `kvp\->last_match` is not set to `0`, that means that we didn't have an exact match and can immediately tell that we don't have the key in the tree. If we the last
match is zero, we can use the `kvp\->position` to get the actual value from the page. This is handled by `btree_get_entry_at()`, which is shown in <<btree_get_entry_at>>.

[source]
[[btree_get_entry_at]]
.`btree.c` - Get the entry by index from a B+Tree page
-----
include::./code/btree.c[tags=btree_get_entry_at]
-----

We are simply reversing the entry write process and unpacking the data from the entry. Note that we could probably come up with a entry format that might be cheaper to unpack
and process, but this is very space efficient and simple and provide us with the great sets of behaviors (can read & write independent of any other values, easy to write and parse,
easy to debug, etc). There is also the convenience function `btree_get_val_at()` which make it easier to get just the value, something that we often need to do.

[NOTICE]
.Reading is easy and simple in B+Tree
====
You might have noticed that the reading portion of the B+Tree is shorter, simpler and much easier to understand and run that the write part. This is not really a true reflection of
how such things really behave, to be fair. Most of the code and complexity in writing to a B+Tree comes from the edge cases, when we need to split a page. The process of writing to
the B+Tree when we _don't_ need to split the page is very straightforward. Almost identical to the reading workflow. 

The good thing about the reads being simpler is that they are also _cheap_. And in most scenarios, you are going to be reading a lot more than you'll be writing. Even when we have a
lot of writes, though. We'll pay the extra cost of page splits only once every few _hundreds_ operations, so it is highly amortized cost. 
====

=== Dropping the B+Tree

The order of sections in this chapter may appear strange to you. We started by showing how to create the B+Tree, spend a _lot_ of time working through the intricacies of writing to
the B+Tree and then moved to seeing how we read from the tree. Now we are dropping the tree entirely? We are actually missing a few important features, namely deleting items and 
iterating over the tree. 
I'm trying to manage the amount of complexity that I'm throwing all at once by putting some of the easier pieces in the middle.

Dropping a B+Tree means that we need to free all the pages and resources associated with it. That task turns out to be fairly simple, as you can see in <<btree_drop>>.

[source]
[[btree_drop]]
.`btree.c` - Dropping a B+Tree by recursively freeing all of its pages
-----
include::./code/btree.c[tags=btree_drop]
-----

The code in <<btree_drop>> runs over the entries in a branch page and recurse into each of them. Whenever we hit a leaf page, we free it and then we go up the tree. This is a simple
depth first search that will end up freeing all the pages in the tree. I like the simplicity, because we can ignore the _contents_ of the pages or their structure. We can just follow
the links and free the pages that we no longer need.

With this brief respite, let's move back to one of the more complex aspects of B+Tree, deleting entries.

=== Deleting from the B+Tree

You might have gathered that deleting items from the B+Tree is not a trivial task. This is only partially correct. Deleting items from the B+Tree is actually very easy, the complexity
starts when we need to merge pages. A page split happens when a page is too full and we can't add any more entries to it. A page merge happens when an entry is deleted from a page and
we take advantage of the additional space to merge two adjacent pages together. Why do we want to do that, if this is so complex? 

* Merging pages reduce the amount of pages that the B+Tree takes, reducing the disk size we need.
* Merging pages can reduce the _depth_ of the B+Tree, which means that we can do less work to find and work with the tree.

The deletion process starts in `btree_del()`, shown in <<btree_del>>.

[source]
[[btree_del]]
.`btree.c` - Deleting an entry by key from the B+Tree
-----
include::./code/btree.c[tags=btree_del]
-----

Our good friend `btree_get_leaf_page_for()` is there, finding up the right leaf page to start working on. If we `del\->last_match` isn't zeroed, we don't have an exact match and can stop
the process. If there is an exact match, we call to `btree_remove_entry()` to do the actual removal of the entry. Finally, in `btree_maybe_merge_pages()` we do the actual page merging, if
we can.
Let's look first at what it takes to remove an entry from a page, this is shown in <<btree_remove_entry>>.

[source]
[[btree_remove_entry]]
.`btree.c` - Removing an entry from a page
-----
include::./code/btree.c[tags=btree_remove_entry]
-----

There isn't much going on in `btree_remove_entry()`, we zero the relevant entry, shift the `positions` array to remove the `position` we are removing from the page and updating the page's
metadata. Removing an entry from a page is not a big deal, but the problem is how do we recover the space when a page is completely empty, or how do we re-balance the load between pages
as data is written and deleted.

.Data access patterns considerations
****
One of the things that we have to take into account when building the B+Tree is what kind of access patterns should we expect and optimize for. 
A good example is building good support for writing data in a sequential manner. You saw in the `btree_split()` that we have taken that into account and optimize the process of adding a
splitting a page where the value is always growing (or decreasing). 

When _deleting_ items, we have to consider one of the following options:

* A queue like system. New entries written the end of the B+Tree and remove them from the front. 
* A stack like system. Writing entries to the end of the B+Tree and remove them from the end.
* Random deletes - may happen everywhere in the tree. 

In this case, I'm referring to the start and the end of the B+Tree in terms of the sorted values, mind. As much as possible, we want to avoid merging those pages if we can. The reason
for that is that they tend to be very commonly used as the targets of deletes.

In the case of a queue like structure, we'll be appending to the end and removing from the front. Merging the first page will just cause us to do more work. For that reason, we only
merge adjacent pages if they are in the middle of their branch page. 
****

The page merge process starts at `btree_maybe_merge_pages()`, which is shown on <<btree_maybe_merge_pages>>.

[source]
[[btree_maybe_merge_pages]]
.`btree.c` - Deciding whatever we should merge the current page with its next sibling
-----
include::./code/btree.c[tags=btree_maybe_merge_pages]
-----

The code in `btree_maybe_merge_pages()` is mostly concerned with deciding whatever we _should_ merge the page with its sibling. We filter out pages that don't have enough free space, we
bail out early if we are already at the root page or if the current page is at the first or last position in its parent page (see the sidebar discussion on that). We also check that
the pages we merge have the same type. We cannot merge branch and leaf pages together, after all.

If we passed all of these checks, we proceed to the `btree_merge_pages()` to do the actual merging. The code for page merges is shown in <<btree_merge_pages>> but I want to focus on
something quite important first. The whole _point_ of `btree_maybe_merge_pages()` is to avoid or delay, as much as possible, the process of page merging. We are trying to avoid page 
splits because they are expensive, the increase the depth of the tree (which requires additional searches), they use more disk space, etc. Why would we want to reduce page merges, though?
With page merges, we are _reducing_ the depth of the tree, so that is a _good_ thing, no?

The issue is, again, related to the expected access patterns that we are likely to see and https://en.wikichip.org/wiki/schlemiel_the_painter%27s_algorithm[Schlemiel's Algorithm]. 
The issue is that deletes tend to either be completely random and come in clumps. We want to avoid doing merge work on each delete, because that can cause a delete of N items to cause
us to do `O(N~2~)` work. For that reason, we attempt to delay the merges as much as possible. 

You can see the same line of thinking in <<btree_merge_pages>> as well, since we do work to delay the _next_ call as much as we can. There is an important assumption we can make in 
`btree_merge_pages()`, we are getting two pages and they are _in order_. In other words, the `p2` data entries all come after the entries in `p2`. That turns out to be very helpful in
reducing the overall complexity.

[source]
[[btree_merge_pages]]
.`btree.c` - Merging two sibling pages (or re-balancing their entries)
-----
include::./code/btree.c[tags=btree_merge_pages]
-----

The code in `btree_merge_pages()` is straightforward, we make sure that the `sibling` and is ready for modifications and then  call to `btree_balance_entries()` to re-balance
the entries and then either remove the empty `sibling` page (if we emptied it from all its entries) or update the `parent` if there are still entries in the `sibling` page. 
I think we should first look at `btree_balance_entries()` ,shown in <<btree_balance_entries>>, to understand how it works and then we can discuss the way page merging works with
better understanding of how the whole machinery works.

[source]
[[btree_balance_entries]]
.`btree.c` - Moving as many entries from `p2` to `p1` as can be fitted.
-----
include::./code/btree.c[tags=btree_balance_entries]
-----

In `btree_balance_entries()` we copy the entries from the `p2` page to `p1`. If you'll recall, we know that all the entries in `p2` are greater than the ones in `p1`, so we can
simply copy the entries from the start of `p2` to the end of `p1` without needing to do anything else to maintain the sort order.
We are copying from the `p2` page until we run out of either entries on `p2` to copy or space to copy to in `p1`. Once that is done, we can remove all the entires that we copied 
from `p2` in one shot. We are using this approach to avoid the cost of removing one item at a time, which can lead to `O(N~2~)` complexity.

.Why am I so careful about zeroing the memory?
****
I'm not sure if you noticed, but I'm trying to be very careful about zeroing out any memory that we have cleared. This isn't actually required, we don't rely on the contents of 
bytes on the page that aren't actively being used. But I'm making sure that whenever we delete an entry from the page, we'll immediately zero it. Why go to the trouble?

One side of this is about security, if we zero the old data immediately (which will be written to disk) we can be sure that deleted records are not hanging around after they are
no longer wanted. This is a minor concern, to be honest. If you care about the security of your system, encryption is where you want to go, not zeroing the memory. You can probably
_still_ recover the data from the disk after we overwrote it with zeros, if you try hard enough.

The more practical reason is that it make it very easy to avoid accidentally using the space after it has been freed. By making sure that it is freed, we can catch such issues
much earlier.
****

Now that you saw how the key components of the page merge process work, let's talk about the implications of this design. We'll only consider a page to be a merge candidate if it
has at least 2.7KB of free space. Given that the maximum size of an entry is 524 bytes (and most are _much_ smaller), that means that when we consider a merge between pages, we'll
copy quite a few entries all at once. 

We always copy down, so when we need to merge a page, we'll look at the _following_ page (with larger entries) to supply us with additional entries to fill the page. A better 
might test the previous and next pages and see if we can find a good candidate, but that complicates the code and doesn't usually end up being very beneficial for real world scenarios.
We are avoiding the top and bottom pages in a branch page as starting points for page merges, that is to optimize common behaviors of deleting from start / end in a sequential manner.

We are also being conservative with the merge process. When we merge, we merge a _single_ page at a time and we don't attempt to probe additional pages to see if we can merge them. 

The final step in the merge process is updating the parent page. This is done in `btree_merge_pages()` by removing the old entry of the `sibling` page from the parent and inserting
the new first key in the `sibling` page. An interesting issue that may arise in this case is that the act of changing the key pointing to the `sibling` page may actually cause us
to split the _parent_ page. This is already handled by the code, so we don't have to take any action, but it is important to understand the potential cascading affects that we have
in the B+Tree.

Let's take a last look at <<btree_maybe_free_empty_page>> where you can see how we handle reducing the depth of the tree. In `btree_maybe_free_empty_page()` we check if the page
we are working with was completely emptied. This can happen if the page we removed items from was the first or last in the parent page (since we aren't merging these) or if the
page was a leaf page adjacent to a branch page, etc. 

[source]
[[btree_maybe_free_empty_page]]
.`btree.c` - Removing an empty page from the tree
-----
include::./code/btree.c[tags=btree_maybe_free_empty_page]
-----

When we remove a page, we have to update the parent page, this is done in `btree_remove_from_parent()`. This is also where the merge process turn recursive and we check if we 
need to merge the parent page (and in turn, the grandparent, etc). You can see how that works in <<btree_remove_from_parent>>.

[source]
[[btree_remove_from_parent]]
.`btree.c` - Remove a page from the parent page, fixup the tree if needed
-----
include::./code/btree.c[tags=btree_remove_from_parent]
-----

The code in `btree_remove_from_parent()` is doing a whole bunch of things all at once, so let's try to list them in order. We start from just removing the entry from the parent
page. Here we have to be careful about structure of the tree. If we removed the leftmost entry, we will replace the new leftmost entry with an empty key (which we represent using
the `∅` sign). The idea is that the leftmost key in a branch page should be the `∅` (smaller than anything) and we maintain that during the merge process. This is important since
deleting entries from the start will lead us to repeatedly remove the leftmost page. By ensuring that the leftmost entry is always the empty key, we can keep the tree ready for
new writes at the start of the tree.

The next step is to recursively call to `btree_maybe_merge_pages()` to see if we can merge the parent page as well. Once that is done, we check if the parent hsa a single entry
in the page. If this is the case, we can simply copy the child page to the parent page and remove the child. This is the stage where we are actually reducing the depth of the 
tree.

This concludes the merging process for pages on delete and we are nearly done with understanding how B+Tree works. There is just one last thing we need to go over, iteration
over the B+Tree data...

=== Iterating over the B+Tree entries

We have done all the work that is required to allow reads, writes and deletes on the B+Tree. I think that you can agree that comparing the complexity to the Extendible Hash
Table we implemented previously, the B+Tree is a lot more complex. But in terms of the functionality we have so far, it isn't really that interesting. We can also do
writes, reads and deletes using the hash table, and it is a lot less complex. What is the _point_ of using a B+Tree?

The most important property of a B+Tree is that it is sorted. That means that when we search a key in the B+Tree, the cost is `O(~log~N)`. More important, it means that we
can iterate through the entires in the B+Tree in sort order. The API we have for iteration on the B+Tree is shown in <<btree_cursor_api>>.

[source]
[[btree_cursor_api]]
.`gavran/db.h` - API for iterating over the entries in a B+Tree
----
include::../include/gavran/db.h[tags=btree_cursor_api]
----

You can learn quite a lot from the API in <<btree_cursor_api>>. Unlike our previous iteration API, we now have a dedicated structure for iteration on the B+Tree. This is
required because we need to maintain the state of the iteration between calls. The API allows us to start the iteration from the start or end of the tree and iterate 
in ascending and descending order. 
We also have the option of starting the iteration from a given key using `btree_cursor_search()`. 
It is also important to note that once we are done using the cursor, we _must_ free it using `btree_free_cursor()`. 

Before we dive into the implementation of iteration on the B+Tree, I think a usage example would be a better idea. Take a look at <<get_last_hour_entries>>, where we are
showing off a 

[source]
[[get_last_hour_entries]]
.`btree.c` - Iterating a B+Tree from a particular point in time
-----
include::./code/btree.c[tags=get_last_hour_entries]
-----
