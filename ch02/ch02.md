
# At the file system level

Files are a wonderful abstraction, a stream of bytes that reside under name, sorted in a hierarchy. Simple enough that a child can use it, powerful enough to be
the motto of an the entire set of operating systems. Everything is a file is one of the defining features of Unix, but it is also an abstraction, and as such, 
it is leaky^[https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/].

When building a storage engine, we need to have a pretty good idea about how to manage files. As it turns out, there is a lot of things that are likely wrong 
about how we think about files. The "All File Systems Are Not Created Equal: On the Complexity of Crafting Crash-Consistent 
Applications"^[https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-pillai.pdf] paper tested ten applications (from SQLite to Git to PostgreSQL)
to find whatever they are properly writing to files. This paper is usually referred to as the ALICE^[Application-Level Intelligent Crash Explorer] paper, after 
the name of the tool created to explore failures in file system usage. 

There are a _lot_ of details that you need to take into account. For example, you may consider that changing a file and then calling `fsync()` will ensure that
the changes to the file are made durable, and that is correct, if you haven't changed the file size. Because while the file data has been flushed, the file 
_metadata_ was not. Which may mean some fun times in the future with the debugger.

> **Testing actual behavior is _hard_**
>
> At one point we had a RavenDB user that setup a machine with a UPS that could be controlled programmatically and then proceeded to test RavenDB's 
> crash consistency by literally pulling the plug on the machine a few thousand times. That was incredibly useful to ensure that we had the proper 
> understanding on _all_ the failure modes. Those that were documents and those that weren't. 

LWN has some good articles on the topic of making sure that the data actually reach the disk^[https://lwn.net/Articles/457667/] and the complexities 
involved^[https://lwn.net/Articles/351422/]. The situation is made more complex by the fact that this is depend on what OS and file system you use and 
even what _mode_ you used to mount a particular drive. As the author of a storage engine, you have to deal with these details in either of two ways:

* Specify explicitly the support configuration, raise hell if user is attempting to use on non supported configuration.
* Make it work across the board. Much harder than it sounds, but not impossible.

Because working with files is such a huge complex mess, and because it is _different_ across operating systems, we'll hide this complexity behind a
platform abstraction layer (PAL). Listing 2.1 shows the core functions that the PAL expose.

```{caption="High level to mask platform difference when working with files" .c}
typedef struct pal_file_handle file_handle_t;

MUST_CHECK bool get_file_handle_size(const char* path,
		size_t* required_size);
MUST_CHECK bool create_file(const char* path, 
		file_handle_t* handle);
MUST_CHECK bool ensure_file_minimum_size(
		file_handle_t* handle, uint64_t minimum_size);
MUST_CHECK bool close_file(file_handle_t* handle);
const char* get_file_name(file_handle_t* handle);
```

We define an opaque type `file_handle_t`, which is how we'll communicate about files with the PAL. If you are used to C APIs, you might notice something
interesting, the API shown in Listing 2.1 is not doing any memory allocations. The API can fail (invalid file name, wrong permissions, etc), but it won't
have to deal with memory issues. Instead, we ask that the _caller_ will provide us with the memory for the `file_handle_t`. Typical usage of the API 
is shown in Listing 2.2.

```{caption="Using the PAL API to create a file and set its size, then close it"}
int main () {
   size_t size = get_file_handle_size("db/phones");
   file_handle_t* handle = malloc(size);
   if(!handle)
      return ENOMEM;
   if(!create_file("/db/phones", handle) || 
   	  !ensure_file_minimum_size(handle, 128 * 1024) || 
   	  !close_file(handle)
   	  ) {
	      print_all_errors();
	      return EIO;
   }
   free(handle);
   return 0;
}
```

This code should ensure that at the end of the way, we have a file that has a minimum size of 128KB which will retain its size even in the case of an error or
a system crash. That sounds easy enough to do in theory, but require some dancing around to get to it. Right now I'm going to focus on Linux as the implementation
system, but we'll get to other systems down the line. 

The `bool` result and the ability to chain such commands makes for nice API, but we do need to be careful about freeing the `handle` that we allocated. Listing 2.2 
has a *memory leak* where the `handle` will never be freed if we have an I/O error. In this case, we can fix without too much trouble, but in more complex cases, that
can get _really_ complex. Requiring the use of `goto`, multiple state flags, etc. 

A better option is to use the `__attribute((cleanup))__` option, available in Clang and GCC for handling this scenario by ensuring that a function will be called when
a variable goes out of scope. That would allow to implement a `defer` like functionality in C. Listing 2.3 shows how that can be made to work:

```{caption="Using defer to avoid a memory leak" .c}
#define CONCAT_(x,y) x##y
#define CONCAT(x,y) CONCAT_(x,y)
#define defer(func, var) void* \
   CONCAT(__defer__, __LINE__) __attribute__ \
   ((__cleanup__(func))) = var; \
   (void)CONCAT(__defer__, __LINE__)

void free_p(void** p){
  // this is a pointer to the handle, we have
  // to dereference it
  free(*p); 
}

int main () {

   size_t size = get_file_handle_size("/db/phones");
   file_handle_t* handle = malloc(size);
   if(!handle)
      return ENOMEM;
   defer(free_p, handle);
   if(!create_file("/db/phones", handle) || 
   	  !ensure_file_minimum_size(handle, 128 * 1024) || 
   	  !close_file(handle)
   	  ) {
	      print_all_errors();
	      return EIO;
   }
   return 0;
}
```

The `defer` macro ensures that the `free_p` function is called regardless of how we exit the function. Of course, this is a very weak form of `defer`, we can only use 
that on pointers and the method we register must accept a `void**` argument. That is good enough for now for me to keep wanting it around. We'll see how it fits into
the code base. One thing to note here, however, is that accepting this `defer` means that we won't be able to compile using MSVC in C mode, since it has no similar feature.
I think that I can compile this in C++ on MSVC and then be able to use RAII instead without changing everything but our abstractions.

## The file handle

We defined the `file_handle_t` as an opaque type in the header, now let's see how we actually work with this on Linux. Listing 2.4 shows the implementation details.

```{caption="The file handle implementation on Linux" .c}
struct pal_file_handle{ 
    int fd;
    // allcoate just after the struct
    char filename[]; 
};

const char* get_file_name(file_handle_t* handle){
    return handle->filename;
}

MUST_CHECK bool get_file_handle_size(
      const char* path, size_t* required_size) { 
    assert_no_existing_errors();
    size_t len = path ? strlen(path) : 0;
    if(!len) {
        push_error(EINVAL,
            "The provided path was null or empty");
        return false;
    }

    if(*path != '/'){
        push_error(EINVAL, 
          "The provided file: '%s' is not an absolute path",
           path);
    }

    *required_size =  sizeof(file_handle_t) + 
        len + 1 /* null terminating*/;
    return true;
}
```

It turns out that `pal_file_handle`, which is `typedef`-ed to `file_handle_t` is a simple struct hold a file descriptor. But why do we compute the file handle 
size in this manner, this is bacuase the `filename` field is defined as zero legnth value and thus points _past the end of the handle_. 
Take a look at Figure 2.1, which shows the structure of `file_handle_t` implmentation on Linux.

> **Beware the paths**
>
> In Listing 2.4, I'm requiring that the provided path will be an absolute path. Why make this requirement? 
> I'm trying to avoid doing things that we don't need to inside the storage engine. The caller can easily provide the full path, and it turns out that this
> matters.
> 
> Let's assume that we accept the path "db/phones", which is a relative path. It gets resolved based on the current directory, as expected. However, our 
> storage engine is meant to be _embedded_. What will happen if the parent application decide to change its output directory? That will mean that our
> relative file name will point to a _different_ location, which is going to cause unforeseen issues. Better to stop this early.

![The layout of `file_handle_t` in memory on Linux](./ch02/img01.png)

Hopefully Figure 2.1 gives you a more intuative manner of how we put the name of the file immediately past the `file_handle_t` 
value. I'm doing it this way to avoid another pointer field or a separate allocation. All I need here is just one buffer and we can put everything inside 
properly. 


## Creating a file

One of my primary goals is to build the right primitives that we need and get as far away from the file system as I can get. These primitives will abstract 
the different nature of file and operating systems. We'll get to the point where we have a small set of actions that we can perform and then build the rest 
of the system on top of that.

> **Why not use a block device**
>
> Technically speaking, the model that I intend to use will work just as well for raw block devices as it would do for files. Indeed, there are some
> real benefits of bypassing the file system for a storage engine. What I most want from a file system as a storage engine is that it will 
> _get out of my way_. There are also some performance benefits, avoiding the need for data fragmentation, overhead of the file system, etc.  
>
> That said, working with files is _ever so much_ easier. Yes, you can use commands such as `dd` to move data between blocks and files, but that
> tend to be much more awkward than if the data reside in a file. In fact, we are going to try hard to get to the point where we have as few files
> as we can get away with.

The act of creating a file is a non trivial operation, since we need to make sure that the file creation is atomic and durable. Beyond what was already 
mentioned, you need to take into account users who pass invalid values (file name containing `/`, for example), _all_ the intricacies of soft and
hard links, size quotas, etc. Further reading in LWN about the issue^[https://lwn.net/Articles/686789/] will probably turn your hair gray. 
To keep the code size small and not overburden ourself with validation code, I'm going to state that I'm trusting the 
callers of the API to have already done the validation of the data. As you can see in Listing 2.4, we are only doing minimal validations to prevent
accidents, not trying to protect against malicious input.

On Linux, once you opened a file, you no longer have access to its name. It may have multiple names (hard links) or non (anonymous or have been deleted). 
As such, the `get_file_handle_size` requests enough space to store the name that the called passed us as part of the same allocation of `file_handle_t`.

> **The file handle abstraction**
>
> On Linux, `file_handle_t` is defined as a struct containing a single `int` and followed by a `char*` buffer holding the null terminated string of 
> the file. On Windows, on the other handle, the definition will use a `HANDLE` instead, and we'll get the file name using `GetFinalPathNameByHandle`
> or `GetMappedFileName` instead. I'm trying to keep to an API that I can use on all platforms.

After calling `get_file_handle_size` the caller is expected to allocate enough memory to store the data and then call `create_file` to actually create
the handle. I'm going to talk about the functions in the same way the C compiler process them, so we'll start from the leafs first and build up our
understanding for the big finish when we actually create the file. 

Listing 2.5 deals with a fairly nasty problem with Linux, management of file metadata. In particular, adding a file or change the size of a file will
cause changes not to the file itself, but to its parent directory. Thus, it is possible for you to make changes to a file (incidently increasing its
size), calling `fsync()` on the file and then losing data because the _size_ of the file wasn't properly persist to stable medium. I'll refer you to 
LWN again for the gory details^[https://lwn.net/Articles/457667/]. 

```{caption="Calling fsync() on a parent directory to ensure that the file metadata has been preserved." .c}
static MUST_CHECK bool fsync_parent_directory(char* file){
    char* last = strrchr(file, '/');
    int fd;
    if(!last){
        fd = open(".", O_RDONLY);
    }
    else{
        *last = 0;
        fd = open(file, O_RDONLY);
        *last = '/';
    }
    if(fd == -1){
        push_error(errno, 
            "Unable to open parent directory of: %s", 
            file);
        return false;
    }
    bool res = true;
    if(fsync(fd)){
        push_error(errno, 
          "Failed to fsync parent directory of: %s",
           file);
        res = false;
    }
    if(close(fd)){
        push_error(errno, 
            "Failed to close parent directory of: %s",
             file);
        res = false;
    }
    return res;
}
```

Listing 2.5 has quite a lot of error handling, in fact, most of it is error handing. Why am I being so paranoid about this? To the point I defined
`MUST_CHECK` and elaborate error handling system? The answer is simple, we aim to create an ACID storage engine, one which will take data and _keep_
it. As such, we have to be aware that the underlying system can fail in interesting ways. The ALICE paper has found numerous issue is projects that 
have been heavily battle tested. And a few years ago that have been a case of data loss in Postgres that has been track down to not checking the 
return value of an `fsync()` call. This LWN article summrize the incident quite well^[https://lwn.net/Articles/752063/]. 
If we aim to build a robust system, we _must_ assume that anything can fail, and react accordingly.

What Listing 2.5 does, essentially, is to `open` the parent directory using `O_RDONLY` and then call `fsync()` on the returned file descriptor. This
instructs the file system to properly persist the directory information and protect us from losing a new file.  Note that we rely on the fact that
strings are mutable in C to truncate the `file` value by adding a null terminator for the parent directory (we restore it immediately afterward).
This trick allows us to avoid allocating memory during these operations.

> **The cost of fysnc()**
>
> Using `fsync()`, we can ensure that writes to the disk has actually reached a stable medium. In other words, after `fsync()` was called, we can 
> rest assured that a power failure won't wipe our data. For a storage engine that, as you can imagine, this is a highly desirable property. 
> 
> The issue is that `fysnc()` usage, however, has a *very* high cost. To the point where we'll spend considerable time and effort down the line
> to _reduce_ the number of times we have to call `fsync()`. The primary issue with `fsync()` is that it needs to clear not just the data in our
> file but to effectively flush the entire disk cache. If you have a lot of pending I/O, you will _wait_ until this is completed, and that can
> take a while.

The reason we need to call `fsync_parent_directory` is that to make the life of the user easier, we are going to create the file if it does not
exists, including the parent directory. This is a small thing, but it adds up measurably to the ease of use of the system. Sadly, this is also
a somewhat tedius task. You can see how we approach it in Listing 2.6, where quite a lot is going on.

```{caption="Ensuring that the full path provide exists and the caller has access to it" .c}
static void restore_slash(void** p){
    *(char*)(*p) = '/';
}

static MUST_CHECK bool ensure_file_path(char* file) {
    // already exists?
    struct stat st;
    if(!stat(file, &st)){
        if(S_ISDIR (st.st_mode)){
            push_error(EISDIR, 
                "'%s' is a directory, expected a file",
                 file);
            return false;
        }
        return true; // file exists, so we are good
    }

    char* cur = file;
    if(*cur == '/') // rooted path
        cur++;

    while(*cur){
        char* next_sep = strchr(cur, '/');
        if(!next_sep){
            return true; // no more directories
        }
        *next_sep = 0; // add null sep to cut the string
        defer(restore_slash, next_sep);
      
        if(!stat(file, &st)){ 
            // now we are checking the directory!
            if(!S_ISDIR(st.st_mode)){
                push_error(ENOTDIR, 
                  "'%s' is a file, but expected a directory",
                   file);
                return false;
            }
        }
        else { // probably does not exists
            if (mkdir(file, S_IRWXU) == -1 && errno != EEXIST){
                push_error(errno, 
                  "Unable to create directory: %s", file);
                return false;
            }
            if(!fsync_parent_directory(file)){
                mark_error();
                return false;   
            }
        }

        cur = next_sep + 1;
    }
    push_error(EINVAL, 
      "The last char in '%s' is '/', this is not allowed",
       file);
    return false;
}
```

A lot if going on in Listing 2.6, but most of it is because we have to do everything manually in C. First, we check if the file already exists. If it does
we need to ensure that the path does not lead to a directory. We then start scanning the file path one segment at a time and see if the directory exists
and if we can create it. 
If we need to create a new directory, we make sure to call `fsync_parent_directory` to ensure that a power failure will not cause the directory to go poof.

One thing to note here is the `restore_slash` function in Listing 2.6. This is called via `defer` to revert the null teminator that we set on `filename`. 
Because we are running in a loop the `defer` will be called on each loop interation. _Not_ having `defer` would mean remembering to reset the value in the
case of an error and led to quite a bit of code duplication. And now we can look at Listing 2.7, where the actual creation of the file takes place. 

```{caption="Creating a file in a safe manner." .c}
static char* set_file_name(const char* path, 
      file_handle_t* handle){
    size_t path_len = strlen(path);
    char* filename = (char*)handle + sizeof(file_handle_t);
    memcpy(filename, path, path_len + 1); 
    return filename;
}

bool create_file(const char* path, file_handle_t* handle) { 
    assert_no_existing_errors();
    char* filename = set_file_name(path, handle);
    struct stat st;
    int isNew = false;
    if(stat(filename, &st) == -1){
        if(errno != ENOENT){
            push_error(errno, "Unable to stat(%s)", 
              filename);
            return false;
        }
        isNew = true;
        if(!ensure_file_path(filename)){
                mark_error();
                return false;
        }
    }
    else{
         if(S_ISDIR (st.st_mode)){
            push_error(EISDIR, 
                "The path '%s' is a directory, expected a file",
                 path);
            return false;
        }
    }

    int fd = open(filename, 
        O_CLOEXEC  | O_CREAT | O_RDWR ,
        S_IRUSR | S_IWUSR);
    if (fd == -1){
        push_error(errno, 
          "Unable to open file %s", filename);
        return false; 
    }
    if(isNew) {
        if(!fsync_parent_directory(filename)) {
            push_error(EIO, 
              "Unable to fsync parent directory after"
              " creating new file: %s", 
              filename);
            if(!close(fd)){
                push_error(errno, 
                  "Unable to close file (%i) %s", fd,
                  filename);
            }
            return false;
        }
    }
    handle->fd = fd;
    return true;
}
```

There is a lot of code in Listing 2.7, but not much is actually happening. We first copy the file name from the user's buffer to the memory provided for the file handle.
This ensures that the file name we actually use is using _mutable_ memory, which we own. If the file does not exist, we create the path to the file, as we saw in 
Listing 2.6. If the file exists, we make sure that it is not a directory. I'm trying to go a little bit beyond rudimetry checks here and produce production level code.
It make the code harder to understand, because there is all the extra stuff here, but I want to reproduce the actual code in this book, not just snippets. 

As careful as I am being here, note that there are many scenarios that I'm not trying to cover. Using soft and hard links or junction points is the first example that
pops to mind. And double the work if you need to deal with files or paths that come from untrusted source. OWASP has quite a bit to talk about in terms of the kind of
vulnerabilities that this might expose.

Earlier I discussed wanting to get the proper primitive and get as far away from that level of code, I think that now it is much clearer exactly why I want to get 
to that level as soon as I can.

## Setting the file's size

When creating a file, it is created with zero bytes. That makes perfect sense, after all. There _is_ no data here. When you'll write to the file, the file system will
allocate the additional space needed on the fly. This is simple, require no thinking on our part and exactly the wrong thing to want in a storage engine.

We just saw how hard we have to work to properly ensure that changes to the metadata (such as, for example, changing its size) are properly protected against possible
power failures. If we would need to call `fsync_parent_directory` after every write, we can kiss our hopes for good performance goodbye. Instead of letting the file
system allocate the disk space for our file on the fly, we'll ask it for the space in advance, in well known locations. That will ensure that we only rarely need to
call `fsync_parent_directory`. 

Requesting the disk space in advance has another major benefit, it gives the file system the most information about how much disk space we want. It means that we give
the file system the chance to give us long sequences of consecutive disk space. In the age of SSD and NVMe it isn't as critical as it used to be, but it still matters
quite a bit. Depending on your age, you may recall running `defrag` to gain _substantial_ performance increase on your system or have never heard about it at all. 

Listing 2.8 shows how we request that the file system allocate enough disk space for us. At its core, we simply call to `posix_fallocate` which will extend the file
for us (or do nothing if the file is already large enough). 

```{caption="Pre-allocate disk space by letting the file system know ahead of time what we need" .c}
bool ensure_file_minimum_size(
      file_handle_t* handle, uint64_t minimum_size){
    assert_no_existing_errors();
    const char* filename = get_file_name(handle);
    int rc = posix_fallocate(handle->fd, 0, (off_t)minimum_size);
    if(rc)
    {
        push_error(rc, 
          "Unable to extend file to size %s to %lu", 
          filename, minimum_size);
        return false;
    }
    char filename_mutable[PATH_MAX];
    size_t name_len = strlen(filename);
    if(name_len >= PATH_MAX){
        push_error(ENAMETOOLONG, 
          "The provided name is %i characters, which is too long",
           name_len);
        return false;
    }
    memcpy(filename_mutable, filename, name_len+1);

    if(!fsync_parent_directory(filename_mutable)){
        mark_error();
        return false;
    }

    return true;
}
```

Much of the work in Listing 2.8 is dedicated to calling `fsync_parent_directory`, but not because we call it. The issue is that `fsync_parent_directory` mutate the
filename that is passed to it. It make sure to return things to normal by the time it returns, but it means that we cannot pass it a constant value and expect things
to work and `get_file_name` returns a `const char*`, so we have to allocate (I'm trying to avoid it as much as possible, but that was unavoidable in this case). 
I'm defining an `char` array of `PATH_MAX` to store the value in a mutable fashion and copying the value there. 

_Technically_, I could pass the `filename` value to the `fsync_parent_directory`, I know where the value came from and it _is_ mutable. But the problem is that this
code needs to be able to run in a multi threaded environment. Imagine what will happen if one thread executes `fsync_parent_directory` while another reads the name
using `get_file_name`. We'll get really hard to figure out bugs. 

> **The perils of paths**
>
> In Listing 2.8, I'm using `PATH_MAX` as the size of `filename_mutable`. This is usually defined to be 4Kb in size, which should be sufficent for pretty much all
> needs. Only a very small amount of it is likely to be used and this isn't meant to be used in a deep stack. Note that I'm checking that the length of the name is
> sufficent to fit in there, to avoid smashing the stack. 
>
> There are actually scenarios where `PATH_MAX` is _not_ sufficent. See this post^[https://eklitzke.org/path-max-is-tricky] a full discussion of the perils of 
> using `PATH_MAX`. 

## Closing a file

After quite a journey, we are almost at the end. The only function we are left to implement to be able to compile the code in Listing 2.3 is `close_file`.
And as it turns out, this is fairly simple, as you can see in Listing 2.9.

```{caption="Closing a file handle" .c}
bool close_file(file_handle_t* handle){
  if(!handle)
      return true;

  if(close(handle->fd) == -1){
      push_error(errno, "Failed to close file %s (%i)",
        get_file_name(handle), handle->fd);
      return false;
  }
}
```

The `close_file` function simple call the `close` method and add some additional error handling, nothing more. We aren't tyring to call `fysnc` or do any
fancy things at this layer. That will be the responsabiity of higher tiers in the code. 

One thing that deserve calling out here, an error from `close` isn't theoretical. In almost all cases, whenever you do I/O, you are not interacting with
the actual hardware, but the page cache. That means that almost all the I/O is done in an asynchronous fashion and `close` is one way for you to get 
notified if there have been any errors.

Even with checking the return value of `close`, you still need to take into account that errors _will_ happen. Unless `fsync` was called, the file system
is free to take you writes to a `close`ed file and just throw them away. This is not a theoretical issue, by the way, it happens quite often in many 
failure scenarios. 

## Reading and writing from the file

Now that we are able to create a file and allocate disk space for it, we need to tackle the next challenge, deciding how we are going to read and write
from this file. I'll defer talking about the internal organization of the file to the next chapter, for now, let's talk about the low level interface
that the PAL will offer to the rest of the system. You can see the function declarations in Listing 2.10.

```{caption="API to provide read/write services for the storage engine" .c}
MUST_CHECK bool map_file(file_handle_t* handle, 
    uint64_t offset, uint64_t size, void** address);
MUST_CHECK bool unmap_file(void* address, uint64_t size);
MUST_CHECK bool write_file(file_handle_t* handle, 
    uint64_t offset,const char * buffer, 
    size_t len_to_write);
```

There isn't much there, which is quite surprising. There is a _vast_ difference between the performance of reading from disk (even fast ones) and 
reading from memory. For this reason, database and storage engines typically spend quite a bit of time managing buffer pools and reducing the 
number of times they _have_ to go to disk.

I'm going to use a really cool technique to avoid the issue entirely. By mapping the file into memory, I don't have to write a buffer pool, I can
use the page cache that already exists in the operating system. Using the system's page cache has a lot of advnatages. I have run into this idea
for the first time when reading LMDB's codebase and it is a fundemental property of how Voron (RavenDB's storage engine) achieve it speed. 
I also recommend reading the "You're Doing It Wrong" paper by Poul-Henning Kamp^[https://queue.acm.org/detail.cfm?id=1814327] that goes into 
great details why this is a great idea.

The idea is that we'll ask the operating system to `mmap` the file into memory and we'll be able to acces the data through directly pointer access.
The operating system is in charge of the page cache, getting the right data to memory, etc. That is a lot of code that we don't have to write, which
has gone through literal decades of optimizations.

We could map the memory for both reads and writes, but I believe that it would make more sense to only map the file data for reads. This is to avoid
cases where we accidently write over the file data in an unintended manner. Instead, we create an explicit interface to write the data to the file. 
The `unamp_file` is just the other side of the `map_file` operation, allowing us to clean up after ourselves. 

You can see the mapping code in Listing 2.11.

```{caption="Implementing mapping and unmapping of memory from out data file" .c}
bool map_file(file_handle_t* handle, uint64_t offset,
      uint64_t size, void** address){
    assert_no_existing_errors();
    void* addr = mmap(0, size, PROT_READ, 
        MAP_SHARED, handle->fd, (off_t)offset);

    if(addr == MAP_FAILED){
        push_error(errno, 
            "Unable to map file %s with size %lu", 
            get_file_name(handle), size);
        *address = 0;
        return false;
    }

    *address = addr;
    return true;
}

bool unmap_file(void* address, uint64_t size){
    if(munmap(address, size) == -1){
        push_error(EINVAL, "Unable to unmap!");
        return false;
    }
    return true;
}
```

There really isn't much there in Listing 2.11. We just need to call `mmap` or `munmap` and do some basic error reporting in the case of an error. In 
Listing 2.12, you can see the implementation of `write_file`. 

```{caption="Writing data to the file" .c}
MUST_CHECK bool write_file(file_handle_t* handle, 
      uint64_t offset, const char * buffer, 
      size_t len_to_write){
    assert_no_existing_errors();
    while(len_to_write){
        ssize_t result = pwrite(handle->fd, 
          buffer, len_to_write, (off_t)offset);
        if (result == -1){
            
            if(errno == EINTR)
                continue;// repeat on signal

            push_error(errno, 
              "Unable to write %zu bytes to file %s",
               len_to_write, get_file_name(handle));
            return false;
        }
        len_to_write -= (size_t)result;
        buffer += result;
        offset += (size_t)result;
    }
    return true;
}
```

The `write_file` call is a simple wrapper around the `write` call, with the only difference being that we'll repeat the write until the entire buffer
has been written. In practice, this usually means that we'll only do a single call to `write` which will perform all the work.

You'll note that I'm using two separate methods to interact with the file data. On the one hand, I'm using `mmap` to read the data, but I'm using the
I/O call `write` to write to it. On Linux, that is safe to do, because both `mmap` and the `write` call are using the same page cache and are 
coherent with respect to one another. 

On _Winodws_, on the other hand, that is not the case. Mixing file I/O calls and memory mapped files lead to situation where you write data using the
I/O API which will take some time to be visible using the memory view. For further reading, you can read how I found out about this delightful state
off affairs^[https://ayende.com/blog/164577/is-select-broken-memory-mapped-files-with-unbufferred-writes-race-condition]. When we get to the Windows
side of things, we'll show how to deal with this limitation properly.

## Using our API for storing and retrieving data

We are still very early on in the process, but I think that peeking at Listing 2.12 will show you how far we have come. We are making for use of all
of our functions to store and read data from the file.

```{caption="Writing and reading from a db file" .c}
#define DB_SIZE (128*1024)

static void close_handle_p(void** h){
   if(!close_file(*h)){
      print_all_errors();
   }
}

static void unmap_mem_p(void** m){
   if(!unmap_file(*m, DB_SIZE)){
      print_all_errors();
   }
}
int main () {

   file_handle_t* handle = malloc(128);
   if(!handle)
      return ENOMEM;
   if(!create_file("db/phones", handle)){
      print_all_errors();
      return EIO;
   }
   defer(close_handle_p, handle);

   if(!ensure_file_minimum_size(handle, DB_SIZE)){
      print_all_errors();
      return EIO;
   }
   
   void* addr;
   if(!map_file(handle, 0, DB_SIZE, &addr)){
      print_all_errors();
      return EIO;
   }
   defer(unmap_mem_p, addr);

   const char msg[] = "Hello Gavran";
   if(!write_file(handle, 0, msg, sizeof(msg))){
      print_all_errors();
      return EIO;
   }

   printf("%s\n", addr);

   return 0;
```

Listing 2.12 shows case the use of `defer` again, which is rapdily becoming my favorite approach to dealing with error handling in this codebase.
We create a new database, ensure that it has the right size, map it into memory and then write a value to it using the `write_file` and read from
it using the memory mapped address.

This may seem like a humble beginning, but we are currently building the foundation of our storage engine. In the next chpater, we are going to 
start talking about how we are going to make _use_ of this functionality.

