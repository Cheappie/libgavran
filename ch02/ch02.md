
# Working effectively with the file system

Files are a wonderful abstraction, a stream of bytes that reside under name, sorted in a hierarchy. Simple enough that a child can use it, powerful enough to be
the motto of an the entire set of operating systems. Everything is a file is one of the defining features of Unix, but it is also an abstraction, and as such, 
it is leaky^[https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/].

When building a storage engine, we need to have a pretty good idea about how to manage files. As it turns out, there is a lot of things that are likely wrong 
about how we think about files. The "All File Systems Are Not Created Equal: On the Complexity of Crafting Crash-Consistent 
Applications"^[https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-pillai.pdf] paper tested ten applications (from SQLite to Git to PostgreSQL)
to find whatever they are properly writing to files. 

There are a _lot_ of details that you need to take into account. For example, you may consider that changing a file and then calling `fsync()` will ensure that
the changes to the file are made durable, and that is correct, if you haven't changed the file size. Because while the file data has been flushed, the file 
_metadata_ was not. Which may mean some fun times in the future with the debugger.

> **Testing actual behavior is _hard_**
>
> At one point we had a RavenDB user that setup a machine with a UPS that could be controlled programmatically and then proceeded to test RavenDB's 
> crash consistency by literally pulling the plug on the machine a few thousand times. That was incredibly useful to ensure that we had the proper 
> understanding on _all_ the failure modes. Those that were documents and those that weren't. 

LWN has some good articles on the topic of making sure that the data actually reach the disk^[https://lwn.net/Articles/457667/] and the complexities 
involved^[https://lwn.net/Articles/351422/]. The situation is made more complex by the fact that this is depend on what OS and file system you use and 
even what _mode_ you used to mount a particular drive. As the author of a storage engine, you have to deal with these details in either of two ways:

* Specify explicitly the support configuration, raise hell if user is attempting to use on non supported configuration.
* Make it work across the board. Much harder than it sounds, but not impossible.

Because working with files is such a huge complex mess, and because it is _different_ across operating systems, we'll hide this complexity behind a
platform abstraction layer (PAL). Listing 2.1 shows the core functions that the PAL expose.

```{caption="High level to mask platform difference when working with files" .c}
typedef struct pal_file_handle file_handle_t;

MUST_CHECK bool get_file_handle_size(const char* path,
		const char* name, size_t* required_size);
MUST_CHECK bool create_file(const char* path, 
		const char* name, file_handle_t* handle);
MUST_CHECK bool ensure_file_minimum_size(
		file_handle_t* handle, uint64_t minimum_size);
MUST_CHECK bool close_file(file_handle_t* handle);
const char* get_file_name(file_handle_t* handle);
```

We define an opaque type `file_handle_t`, which is how we'll communicate about files with the PAL. If you are used to C APIs, you might notice something
interesting, the API shown in Listing 2.1 is not doing any memory allocations. The API can fail (invalid file name, wrong permissions, etc), but it won't
have to deal with memory issues. Instead, we ask that the _caller_ will provide us with the memory for the `file_handle_t`. Typical usage of the API 
is shown in Listing 2.2.

```{caption="Using the PAL API to create a file and set its size, then close it"}
int main () {
   size_t size = get_file_handle_size("db", "phones");
   file_handle_t* handle = malloc(size);
   if(!handle)
      return ENOMEM;
   if(!create_file("db", "phones", handle) || 
   	  !ensure_file_minimum_size(handle, 128 * 1024) || 
   	  !close_file(handle)
   	  ) {
	      print_all_errors();
	      return EIO;
   }
   free(handle);
   return 0;
}
```

This code should ensure that at the end of the way, we have a file that has a minimum size of 128KB which will retain its size even in the case of an error or
a system crash. That sounds easy enough to do in theory, but require some dancing around to get to it. Right now I'm going to focus on Linux as the implementation
system, but we'll get to other systems down the line. 

The `bool` result and the ability to chain such commands makes for nice API, but we do need to be careful about freeing the `handle` that we allocated. Listing 2.2 
has a *memory leak* where the `handle` will never be freed if we have an I/O error. In this case, we can fix without too much trouble, but in more complex cases, that
can get _really_ complex. Requiring the use of `goto`, multiple state flags, etc. 

A better option is to use the `__attribute((cleanup))__` option, available in Clang and GCC for handling this scenario by ensuring that a function will be called when
a variable goes out of scope. That would allow to implement a `defer` like functionality in C. Listing 2.3 shows how that can be made to work:

```{caption="Using defer to avoid a memory leak"}
#define defer(func, var) void* \
   __defer ## __LINE__ __attribute__ \
   ((__cleanup__(func))) = var; \
   (void)__defer ## __LINE__ 

int main () {

   size_t size = get_file_handle_size("db", "phones");
   file_handle_t* handle = malloc(size);
   if(!handle)
      return ENOMEM;
   defer(free, handle);
   if(!create_file("db", "phones", handle) || 
   	  !ensure_file_minimum_size(handle, 128 * 1024) || 
   	  !close_file(handle)
   	  ) {
	      print_all_errors();
	      return EIO;
   }
   return 0;
}
```

The `defer` macro ensures that the `free` function is called regardless of how we exit the function. Of course, this is a very weak form of `defer`, we can only use 
that on pointers and the method we register must accept a `void*` argument. That is good enough for now for me to keep wanting it around. We'll see how it fits into
the code base. One thing to note here, however, is that accepting this `defer` means that we won't be able to compile using MSVC in C mode, since it has no similar feature.
I think that I can compile this in C++ on MSVC and then be able to use RAII instead without changing everything but our abstractions.

## The file handle

We defined the `file_handle_t` as an opaque type in the header, now let's see how we actually work with this on Linux. Listing 2.4 shows the implementation details.

```{caption="The file handle implementation on Linux"}
struct pal_file_handle{ 
    int fd;
};

bool get_file_handle_size(const char* path, 
		const char* name, size_t* required_size) { 
    if(!path || !name){
        push_error(EINVAL, 
        	"The path or name are null, which is not allowed");
        return false;
    }

    size_t path_len = strlen(path);
    size_t name_len = strlen(name);

    if(!path_len || !name_len) {
        push_error(EINVAL, 
        	"The path or name are empty, which is not allowed");
        return false;
    }

    required_size = sizeof(file_handle_t) + path_len + 1 
    		/* slash */ + name_len + 1 /* null terminating*/;
    return true;
}


const char* get_file_name(file_handle_t* handle){
    return ((char*)handle + sizeof(file_handle_t)); 
}
```

It turns out that `pal_file_hanlde`, which is `typedef`-ed to `file_handle_t` is a simple struct hold a file descriptor. But why do we compute the file handle 
size in this manner, and how come the `get_file_name` just points _past the end of the handle_ to get the file name?

For Linux, the structure of the `file_hanlde_t` is [int32_t - fd, char[] file name]. That is, we lay the name of the file immediately past the `file_handle_t` 
value. I'm doing it this way to avoid another pointer field or a separate allocation. All I need here is just one buffer and we can put everything inside 
properly.


## Creating a file

One of my primary goals is to build the right primitives that we need and get as far away from the file system as I can get. These primitives will abstract 
the different nature of file and operating systems. We'll get to the point where we have a small set of actions that we can perform and then build the rest 
of the system on top of that.

> **Why not use a block device**
>
> Technically speaking, the model that I intend to use will work just as well for raw block devices as it would do for files. Indeed, there are some
> real benefits of bypassing the file system for a storage engine. What I most want from a file system as a storage engine is that it will 
> _get out of my way_. There are also some performance benefits, avoiding the need for data fragmentation, overhead of the file system, etc.  
>
> That said, working with files is _ever so much_ easier. Yes, you can use commands such as `dd` to move data between blocks and files, but that
> tend to be much more awkward than if the data reside in a file. In fact, we are going to try hard to get to the point where we have as few files
> as we can get away with.

The act of creating a file is a non trivial operation, since we need to make sure that the file creation is atomic and durable. Beyond what was already 
mentioned, you need to take into account users who pass invalid values (file name containing `/`, for example), _all_ the intricacies of soft and
hard links, size quotas, etc. Further reading in LWN about the issue^[https://lwn.net/Articles/686789/] will probably turn your hair gray. 
To keep the code size small and not overburden ourself with validation code, I'm going to state that I'm trusting the 
callers of the API to have already done the validation of the data. As you can see in Listing 2.4, we are only doing minimal validations to prevent
accidents, not trying to protect against malicious input.

```{caption="Computing the required size for a file handle"}
size_t get_file_handle_size(const char* path, 
      const char* name) { 
    if(!path || !name)
        return 0;

    size_t path_len = strlen(path);
    size_t name_len = strlen(name);

    if(!path_len || !name_len)
        return 0;

    return sizeof(file_handle_t) + path_len 
            + 1  /* slash */ + name_len 
            + 1 /* null terminating*/;
}
```

On Linux, once you opened a file, you no longer have access to its name. It may have multiple names (hard links) or non (anonymous or have been deleted). 
As such, the `get_file_handle_size` requests enough space to store the name that the called passed us as part of the same allocation of `file_handle_t`.

> **The file handle abstraction**
>
> On Linux, `file_handle_t` is defined as a struct containing a single `int` and followed by a `char*` buffer holding the null terminated string of 
> the file. On Windows, on the other handle, the definition will use a `HANDLE` instead, and we'll get the file name using `GetFinalPathNameByHandle`
> or `GetMappedFileName` instead.

After calling `get_file_handle_size` the caller is expected to allocate enough memory to store the data and then call `create_file` to actually create
the handle. Listing 2.5 shows the details of this function. I'm going to go over the details from the top down, because there is quite a _lot_ of it
to go through, I'm afraid.

```{caption="Creating a file in an durable manner" .c}

```