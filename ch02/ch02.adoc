= Part I - The foundation of Gavran

In this part, we'll deal primarily with building the lowest levels of Gavran. How it writes to disk, what the data format is, etc. You already saw
<<foundation_structure>>, which sheds some light on the architecture of the foundation. 

The foundation starts at the PAL (Platform Abstraction Layer) and builds on top of that to implement ACID transactions, space management and much more.
The design of Gavran calls to moving as much as possible into the foundation. We want to ensure that we have implemented the required functionality for
a proper storage engine as deeply as possible. This is to ensure that higher level pieces don't need to deal with that issue.

For example, in Gavran, we implement MVCC (Multi Versioning Concurrency Control) at the foundation layer, meaning that higher tiers don't need to concern
themselves with it. This is in contrast to PostgreSQL, for example, where the MVCC is done at a much higher level and a transaction needs to actively 
filter data that is already out of date or shouldn't be visible yet. 

Before we can get started implementing Gavran, however, we have to deal with a tenacious problem. We first need to deal with C's greatest weaknesses:

* Error handling.
* Resource lifetime and disposal.

For a very long time, I was working in a managed environment. The usual gymnastics that you have to go through in order to get errors or properly manage
resource disposal right in C is _not_ nice. I'm going to dedicate the very start of the project to get something that I think is much better going on.

== Errors handling and resource management infrastructure 

Error management in C is a manual (and tedious) process. The common method is to return an error code to the caller, which may decide how to handle that. 
Along the way, we lose a _lot_ of contextual information. The `EBADF` error tells me that there is a bad file, but it doesn't tell what the file _name_ is, 
for example. Such details can make the difference from: "Oh, sure, easy fix" to "Well, I better make some coffee and start debugging this...". 

:attribute_cleanup: __attribute__\((__cleanup__))

[IMPORTANT]
.Error handling & resource management are critical infrastructures
====
We expect to write non trivial amount of code in this project and we'll do a lot of low level work here. In order to ensure that we have a chance of getting
to the end, we _must_ have a good way to handle errors and manage resources. 

That is why the very first action I'm making in this book is explaining all about _error handling_. Even before we actually thought about what we'll be 
building!

I have taken inspiration from the Rust language `try!` macro (later shortened to `?`) and from Go's `defer` calls. The idea is that as much as possible, we
want to push error handling and resource management into the infrastructure. I'm using several compiler features to enable this style of work, in particular,
using  `{attribute_cleanup}` to enable automatic resource cleanup, similar to RAII in C++, but when writing plain C code.
====

I want to first illustrate that with the sample code in <<read_int_to_str_buffer>> and then discuss exactly what is going on here. In <<read_int_to_str_buffer>> 
we have a function that reads 4 bytes from a file and convert these bytes into a string format. The task itself is nonsensical, meant to just illustrate a point. 
There are a bunch of things that can go wrong in this kind of code. We may fail to open the file, or allocate memory. We may fail to read from the file, or not read enough, 
etc. We need to remember to always close the file descriptor and we should always free the allocated buffer on error, but not if the function 
completed successfully.

That is a _lot_ of state to manage, and it makes it easy to make mistake. <<read_int_to_str_buffer>> shows a function that has to deal with coordination across merely two
resources. If we have to deal with more, the situation worsen. Take a look at the code and then we'll break down everything that is new here.
I have marked on the side all the interesting tidbits, so we can discuss them at length.

We'll have a longer discussion of the API used here in just a bit, for now, I want you mostly to get the _impression_ of how this code is put together, rather than deal
with the details.  The API in <<read_int_to_str_buffer>> forms the basis of error handling and resource management strategy for the upcoming storage engine. Let's see what 
it does and then we'll discuss how they all fit together. I'll discuss how they are _implemented_ in the next section.


[source]
[[read_int_to_str_buffer]]
.test.c - Mostly automatic handling of resource usage and error handling in C
----
include::./code/test.c[tags=read_int_to_str_buffer]
----
<1> The `result_t` type is the return type for any function that may fail. It is an opaque type that is set to zero on failure and non zero of success. Using C's
usual rules, we can use boolean operations on this value to test for success / fail. A key factor about `result_t` is that it is a value that _must_ be observed. 
In other words, ignoring this value will result in a compiler error using our settings. 

<2> The `failed` macro is used to report errors. A call to `failed` will exit the function with a fail status and the parameters to `failed` 
will be used to generate an error message. It is expected that multiple methods will fail in a sequence, and the infrastructure is setup to handle this and 
generate appropriate set of errors representing the location in the stack this issue occur on.
You can use `msg` to provide some additional information and `with` to provide more context, such as local parameters. This is how we can see the file name the 
`read_all` was asked to scan, for example. The additional context can make such errors must easier to resolve. It is important to note that they are _not_
evaluated if the operation completed successfully.

<3> The `defer` and `try_defer` allow us to register a function to be called when the current scope ends. This capability uses the `{attribute_cleanup}` feature
in GCC and Clang and it is how we intend to manage resources in general. Freeing ourselves from having to deal with them at every turn. The `try_defer` macro also
allows us to _cancel_ this operation. We'll see discuss why this is important shortly.

<4> The `ensure` macro will check that a particular operation was successful (has non zero value) and will exit the function with an error if that isn't the
case. This reduce nesting in the function and make it easier to both read and write.

<5> The `success` macro allows us to exit a method successfully.


If we call `read_int_to_str_buffer("/path/to/directory", &buffer);` function (note that we used the path of a directory, not a file) we'll have the following 
sequence of events:

* The directory is opened.
* The memory is allocated.
* The read fails.
* Everything gets cleaned up.
* Caller can call `errors_print_all()` to get the following output:
....
read_all()                - test.c:29  -  21 Is a directory   | Failed to read requested data, read_bytes = 0, cur = -1, size = 4

read_int_to_str_buffer()  - test.c:53  -  22 Invalid argument | read_all(fd, sizeof(int), &val), path = /path/to/directory
....
* Callers can also use `errors_get_codes()` or `errors_get_messages()` to interact with the errors stack programmatically. 

You'll note that we get a _lot_ of information here. This is _almost_ a stack trace and the richness of exceptions, without any of the costs associated with it.
We are also able to print out the current state at the time of the error, which can be _invaluable_ for debugging and troubleshooting.

There are several things that work together here in order to enable this style of code:

* All the functions return `result_t`, which must be checked.
* Error reporting is done via `failed`. And completion with no error is marked via `success`. 
* While you can check explicitly, you'll usually just use `ensure` to exit if the call has failed.

All of those together create a system that operate almost like exceptions. I don't need to manually handle and pass errors up the chain, I don't have to fret
about how to provide context to an error, etc. 

.Inspirations for these ideas
****
The errors API concepts are very similar to how you deal with errors in https://en.wikibooks.org/wiki/OpenSSL/Error_handling[OpenSSL]. I had the chance
of building completely new API so I stream-lined a lot of things, but the concepts are very similar.

The `defer` usage comes from Go, although I added the notion of `try_defer` for more complex scenarios.
****

You'll notice that in the `read_int_to_str_buffer` function we do almost no explicit error checking, this is done for us by the `ensure`. The one case where we do have
to test a value explicitly is when we are dealing with system code, when we are checking if the `open` was successful, then calling `failed` with the error.
We want to push the things that can fail in this manner as deeply as possible, so we'll be able to use the `ensure` macro to reduce the amount of 
explicit error handling we have to go through.

This style of error handling is problematic in C, because we can't just _exit_ a function, we have to do cleanup first. In pretty much any C project of any 
complexity you'll see `goto` used for this approach, to try to centralized error handling in the function. This resource management strategy is brittle and hard
to use. Instead, we offer `defer` and `try_defer`. 

[CAUTION]
.Here `goto` is the _good_ option!
====
You probably heard about the "GOTO Considered Harmful" paper and likely have an aversion to this keyword. However, in most C projects, the use of a `goto`
for error handling is the _preferred_ option. Because the other alternative is much worse, manually maintaining complex and brittle resource & error management code.
====

The `defer` and `try_defer` are based on `{attribute_cleanup}` extension for both Clang and GCC. This is a way to instruct the compiler to call a method 
when a variable goes out of scope. We use this approach to ensure that we have proper cleanup. For example, making sure that regardless of how we exit the 
`read_int_to_str_buffer` function, the file will be properly closed.

In `read_int_to_str_buffer` there is another resource usage pattern that we need to deal with. The buffer we allocate to hold the string must be released in case the 
function fails, but must _not_ be release if the function is successful. 
In order to handle this kind of scenario, we have `try_defer`, it accepts an additional argument, that of a variable that it will monitor when called. If that variable is set, 
we'll cancel the deferred call. In other words, we'll be able to cancel the deferrable command in the successful path, but until that point, we'll have automatic cleanup. 

These two approaches together leads to a much cleaner codebase. And now, let's see how I actually built those. 

=== Implementing resource management

I'll start with the `defer` commands, because they are the smaller of the two. Mostly they just give good syntax over the compiler behavior. You can see how they
are implemented in <<defer-api>>.

The idea is that we setup a call to `void defer_<function>(struct cancel_defer* cd)` function. That will be called by the compiler when the scope exits. This
The caller is responsible for providing this function. I would prefer to avoid it, but trying to do so send us _deep_ into preprocessor magic, and I'm already
stretching the limits of what I think is acceptable. 

<<defer-define>> shows how we can use these macros to define functions that will be called automatically. We implement `defer_free` explicitly, but use the
`enable_defer_imp` to create an implementation of the `defer_close` call. This allows us to call `defer(free, ptr)` or `defer(close, fd)` and have the right
thing happen automatically.

[source]
[[defer-api]]
.defer.h - Implementation of defer and try_defer using the {attribute_cleanup}
```
include::./code/defer.h[tags=defer]
```
<1> The `cancel_defer` struct allow to capture the state that will be sent through the `defer` call as well as the pointer to the cancellation flag.
<2> The actual macro implementing `try_defer` and `defer`. Note that we set the `cancelled` field to track the marker value provided by the caller.
<3> The `defer` macro is implemented in the same manner, but without setting the `cancelled` field. 
<4> Helper macros to add `defer` support for other functions. We'll see how this is used shortly.

We provide our own implementation on `free` manually because `free` cannot fail, so it returns a `void` which we can't compare on. If your functions use the 
conventions outlined here, you can simply use `enable_defer(func_name)` and you are set.

[IMPORTANT]
.We are capturing the _address_ of the `defer` argument
====
It it important to note that `defer` does something different than `{attribute_cleanup}`. While the later capture the value at the time of the call, we capture
the _address_ of the variable that is passed to `defer`. That means that when the deferred function is called, we'll operate on the current value of the variable,
not on its original one. 

This can be very important if you are using `realloc`, for example. 
====

[source]
[[defer-define]]
.defer.h - Adding support for calling cleanup functions via `defer`
----
include::./code/defer.h[tags=defer_free]

enable_defer_imp(close, -1, *(int*), "%d");
----

One issue that we have to think about, however, is that the cleanup itself may also fail. And in a "Quis custodiet ipsos custodes?" style, we have to consider
how do we handle errors that happens on `defer`. At this point, the `return` was already called, so we may have a function that completed successfully, but failed 
cleanup. 

We consider such a thing a failure and therefor we check both the return value and the `errors_count()`, to see if there have been any errors after the `return`. 
See the discussion on how `ensure` is implemented in the next section.

=== Building error handling strategy

Moving on to the error handling, we actually have a few levels inside the error handling that we need to consider. There are a few functions that you can
use to _report_ errors:

* `errors_push()` will create a new error and `errors_append_message()` will add additional context to it.
* `errors_assert_empty()` can check if we were called with errors that haven't been observed yet. In this case, we immediately return an error to avoid
  error propagation. 
* The functions `errors_get_count()`, `errors_get_codes()`, `errors_get_messages()` will all inspect the existing errors if you need to do something programmatically
  to them. 
* The function `errors_clear()` marks them as observed and `errors_print_all()` will print them errors to the console and clear them.

On top of these, several macros and being able to rely on `defer` gives us the right behavior. The rest of the work is done mostly by macros, so let's see them in <<errors_api>>.

[source]
[[errors_api]]
.errors.h - Internal errors API implementation
----
include::./code/errors.h[tags=errors_api]
----

A lot is going on in <<errors_api>>, allow me to go through this one at a time. We start by forward declaring `op_result_t`. We don't actually _have_ such 
a struct. We'll be using `result_t`, which is a pointer to an `op_result_t` with the `warn_unused_result` enabled. Because we created a new type, the 
compiler will warn us about trying to assign it to other data types and the `warn_unused_result` will make sure that we can't ignore it.

The reason we declare this type is that the compiler will warn us if we are trying to assign this to any other type. It would generate a warning, and in 
addition to the unused result warning, that ensures that we have a return type that we _have_ to take care of.

The `failed` and `ensure` macros are variadic. They are meant to be used with the `with` and `msg` macros. The idea is that we'll first push a new
error and then be able to provide more context to it. In the case of `ensure`, if the expression is true, there is no cost and nothing is actually
being run. Note that for `ensure`, we also check if `errors_get_count()` is non zero. This is to handle a scenario where we had a `defer` that run
and _failed_ after the function itself was successful. We want to treat this as an error and fail as usual. 

You can also use `verify` to do a proper check if an operation was successful or not. This is used if you need to do some error handling on the operation,
not just return to the caller. The `verify` will ensure that we consider also deferral errors into account before agreeing that the operation was successful.

[NOTE]
.The difference between `op_result_t*` and `result_t`
====
As far as the C compiler is concerned, `result_t` and `op_result_t*` are one and the same. After all `result_t` is a macro that resolves to
`op_result_t*`. The difference between them is that the `result_t` macro also specifies `warn_unused_result`. This is how we force the 
compiler to validate that our errors are not discarded.
====

:file-macro: __FILE__
:line-macro: __LINE__
:func-macro: __func__

The `errors_push` macro just call to `errors_push_new` with context using `{file-macro}`, `{line-macro}` and `{func-macro}` built-ins to provide additional
context for our "stack trace". The rest of the functions aren't anything special. The `errors_push` macro is _not_ variadic, we could implement it this
way, but I would rather have the more explicit usage of `with` and `msg`. 
The nice thing about `with` is that it capture the expression value as well the expression text. That saves us some keystrokes on each error call.

[TIP]
.Forcing error handling
====
Beyond just using `result_t`, we also have the `errors_assert_empty` macro which will can use to check if the caller has previously
ignored an error. If that is the case, we'll refuse to go on and error immediately.  That has the effect of ensuring that errors are handled, because it 
will very visibly break stuff if you don't. 

This is meant for _external_ users. If you called an API method and it failed and you didn't check the error, all future operations will also fail.
That keeps us in the habit of managing errors properly.
====

You'll note that unlike most C APIs, we are missing quite a bit here. Namely, where is the memory handling? In order to reduce as much as possible the
complexity of the system, I have chosen to avoid memory allocations entirely in the errors API. Errors that happens _during_ error handling are among
the chief reasons for high severity issues. There is a interesting paper on the topic that you might want to go through, 
https://www.eecg.utoronto.ca/~yuan/papers/failure_analysis_osdi14.pdf[Simple Testing Can Prevent Most Critical Failures]. In it they find that 92% of the
catastrophic failures are the result of bad handling on non fatal errors. 

At this point, you might understand why I put so much emphasis on proper error handling so early in the process. It is almost impossible to make such a 
change later in the lifetime of a project and the results are _important_. 
We'll start talking about our errors handling implementation with <<errors-impl-declarations>>.

[source]
[[errors-impl-declarations]]
.errors.c - Storage declaration for the errors API
----
include::./code/errors.c[tags=declarations]
----

We define a number of variables as thread local state. The idea is that instead of allocating the memory at the time of an error, we'll allocate the memory 
at the time we create the thread. This is done for us automatically, so by the time we get to actually recording an error, we don't have to fear most failure
modes.

:messages-buffer: _messages_buffer
:errors-count: _errors_count
:messages-codes-buffer: _errors_messages_codes
:errors-messages-buffer: _errors_messages_buffer
:errors-messages-len: _errors_buffer_len
:errors-oom: _out_of_memory

The `{messages-buffer}` is a 2KB buffer that is used to store the actual messages for the errors, while the `{errors-messages-buffer}` is an array that stores
the relevant message for each of recorded array. In other words, the `{errors-messages-buffer}` entries will always point to a location inside `{messages-buffer}`. 
The `{errors-messages-buffer}`, in turn, is a parallel array of the actual error codes that we got. This memory layout is shown in <<errors_layout>>.

.The actual error messages are stored in a thread local buffer that is pre-allocated
[[errors_layout]]
image::./errors-layout.png[]

The `{errors-count}` value counts the number of errors that are currently recorded while `{errors-messages-len}` counts how much of `{messages-buffer}` is in use. 
The size of the buffer is 2KB and the maximum number of errors we can hold is 64. The `{errors-oom}` flag is set if we have too many errors, at which point
we'll start discarding them. I find that very unlikely to actually happen. Very deep stack traces are unusual in C so I don't expect will need even that much.

If you'll look at the API in <<errors_api>>, you can see that aside from `errors_push_new` and `errors_append_message`, all the other functions we offer are about
reading the errors or clearing them. The usual method you'll use the `ensure` / `failed` macros to bubble the errors to the callers until we get somewhere where
we can make a decision about the issue. The caller will need to read the errors and make a determination and then clear the error state and prepare for the next
operation. 

A shorthand for printing to the terminal is provided with `errors_print_all()`, typically for debugging purposes. 
If you need to access the error codes programmatically, you can use the `errors_get_codes()` function. 

Because we are doing no memory allocations and working on a fixed buffer, we need to be careful with how we process the messages. I tried doing that directly 
with the raw C API, but it was too complex to manage. I wrote a couple of utility functions to manage that and if you are interested, I would refer you to 
Howard Chu's (author of LMDB) discussion of https://www.openldap.org/lists/openldap-software/200303/msg00560.html[C string API]. You can see what I did in
<<try_sprintf>>. 

[source]
[[try_sprintf]]
.errors.c - String processing routines
----
include::./code/errors.c[tags=try_sprintf]
----

The key about the functions in <<try_sprintf>> is that they accept a _limit_ to how much they can write, and then do all the checks inside. The end result is that
our code string processing routine looks much simpler, see for yourself in <<error-push>>.

[source]
[[error-push]]
.errors.c - Pushing a new error into the thread's buffer----
----
include::./code/errors.c[tags=errors_push_new]
----
<1> Check if we have more than the maximum number of errors. This is unlikely, in most use cases.
<2> Increment the current error counter. Note that we increment this counter even if we don't have enough memory for the error message. In that case, the error
message will be null, but the error code will be retained.
<3> We call `try_sprintf` multiple times, formatting the error message. This code is a bit complex, since C's string processing capabilities are... awkward. 
A key factor here is that we can safely call these function even if there isn't enough memory, they do their own check and bail out early. This code was 
_much_ harder to follow before I introduced the `try_sprintf` helper. 

The fact that we can limit the number of errors we may run into _during_ error handling is important. None of the error handling routines can generate an error
or require any special treatment. Most of the nastiest issues that I have run into have happened while there was an error in the middle of handling an error.
Reducing the number of possible failure points is very useful.

Now that you have seen how we push a new error, let's see how we provide more context to the error. The backend of the `with` and `msg` macros is the
`errors_append_message` function, shown in <<errors_append_message>>.

[source]
[[errors_append_message]]
.errors.c - Appending a message to the current error
----
include::./code/errors.c[tags=errors_append_message]
----
<1> Here we start from one char _before_ the end. This is so the next write will overwrite the null terminator.
<2> On the other hand, if we wrote to the buffer but hit the end, we'll restore the overwritten null terminator so we won't have an out of bound access on read.

And finally, we have the rest of the errors API implementation in <<errors-rest>>. 

This is a very powerful API, since it allows us to have good error handling with little ceremony. The `errors_append_message` and `errors_push_new` return 
a `op_result_t*` because they might be used via the comma operator. That is a done in the `failure` macro, which is called internally from the `enforce` 
macro.

[source]
[[errors-rest]]
.errors.c - The rest of the implementation
----
include::./code/errors.c[tags=rest]
----

You may find it strange that the very first thing that I did when starting a storage engine is to build error handling code, but that is a foundation that 
will serve us for the rest of the project. The fact that we can have good ways to report error can save us _weeks_ of troubleshooting time. And with this
in place, we can now move to our very first real task, working with files. 

[WARNING]
.The errors API for external consumers?
====
We looked at the error API (and `defer`) in the context of consuming this internally. Gavran, our storage engine, is meant to be an embedded library.
That means that it is going to be used from other systems. Forcing our error convention on unsuspecting code bases is not something that I would consider
desirable. 

From the outside, users have an API very similar to https://www.openssl.org/docs/man1.0.2/man3/err.html[OpenSSL]. You can check the status code of the 
operation using a return code and if you need more details, you can call the dedicated errors API to get more information.
====

=== Testing the error API

I intend to close each chapter with a set of unit tests, verifying the functionality of the system that we built so far.

Testing C isn't a lot of fun, but it is important. I initially tried to build the test framework using Python, but I realized that I spent more time debugging 
`cyptes` issues than anything else. What was worse, when the test showed a failure, I would have to rebuild it in C and then debug it, rather than work through
the tests directly.

I'm going to be using the https://github.com/mortie/snow[Snow] testing framework, which gives us nice API to work with and makes it easy to debug and monitor 
the tests. For example, we are going to run all our tests through `Valgrind` as a matter of course, so we can verify that there are no memory issues. 

You can see the actual tests in <<testing_errors_and_defer>>. We are testing the full functionality of our system so far. Right now, it doesn't mean much, but
as we'll build more and more functionality, this is going to be incredibly valuable in ensuring that we don't have to deal with 

[source]
[[testing_errors_and_defer]]
----
include::./code/test.c[tags=tests_02]
----

And the output of the tests is shown below. Not that I'm running them in Valgrind to make sure that everything is okay in term of memory utilization. On the first
run, I didn't initialize `cancel_defer` to zero, so Valgrind pointed out that I'm using uninitialized memory, which was very useful. 

....
==20213== Memcheck, a memory error detector
==20213== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==20213== Using Valgrind-3.16.1 and LibVEX; rerun with -h for copyright info
==20213== Command: ./build/gavran
==20213== 
==20213== error calling PR_SET_PTRACER, vgdb might block

Testing errors_and_resource_usage:
 Success: Can setup defer to happen automatically (8.12ms)
 Success: Can cancel deferral defer to happen automatically (1.59ms)
 Success: No errors should return zero count (1.37ms)
 Success: Can record error (28.20ms)
 Success: Max 64 errors (12.91ms)
 Success: Very large errors won't overflow (24.60ms)
 Success: Will translate codes to strings (5.72ms)
 Success: Can call function and get error back (12.14ms)
errors_and_resource_usage: Passed 8/8 tests. (150.35ms)

==20213== 
==20213== HEAP SUMMARY:
==20213==     in use at exit: 0 bytes in 0 blocks
==20213==   total heap usage: 6 allocs, 6 frees, 5,019 bytes allocated
==20213== 
==20213== All heap blocks were freed -- no leaks are possible
==20213== 
==20213== For lists of detected and suppressed errors, rerun with: -s
==20213== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
....

And that is quite enough for one chapter. In the next chapter we'll start dealing with the operating system and build the basics of the platform abstraction
layer that will help us interact with the rest of the system.