
# Low level data format

In the previous chapter, we built up the transaction API and were able to modify a page and persist it back. At this point, the code we have makes absolutely no 
assumptions about the data we have on disk. We operate on the data in page units and blindly. This cannot go on, because we can't expect the users to know how to 
manage the pages and their content by themselves.
We need to be able to allocate and free pages. Once we have that, we can build more sophisticated data structures. 

The API we want to have are:

* `MUST_CHECK bool allocate_page(txn_t tx, page_t* page);`
* `MUST_CHECK bool free_page(txn_t* tx, page_t* page);`

Let consider what we actually need to do in order to implement this functionality. We need to persist somewhere that pages are taken or free. We need to be able
to search for a free page and we need to be able to mark a page as free. That means that we are going to store that information in the file itself. And that lead
to a bunch of questions. How are we going to do this? What would be the format of the data? How well will it play with future features?

We want to create a system that will serve for the foreseeable future, we want to ensure that it plays nicely with the API we created so far and that is doesn't
require complex implementation. We are too low in the stack yet to be able to do truly interesting things. The whole point of this book is to build the features
one on top of the other. 

## The file header

Looking at the API above and how we can implement them, I think we'll the following information:

* The size of the file in pages - we need to store that information inside the data file because relying on the size of the file as reported by the operating
  system cannot serve us for long. If we failed after the file size was extended but didn't update our internal metadata, we'll probably not enjoy the result.
* A way to tell if a page is free or in used.

Right now we need to keep track of only one piece of data about the file, its size in pages, but I'm sure that we'll have more in the future. To handle that
we'll create the following structure to serve as the header for the file and be the metadata location. You can see how the first version looks like in 
Listing 4.1.

```{caption="The file header structure contains metadata about the file" .c}
#define FILE_HEADER_MAGIC \
	(9410039042695495) // = 'Gavran!\0'

typedef struct file_header {
    uint64_t magic;
    uint64_t number_of_pages;
    uint32_t version;
    uint32_t page_size;
} file_header_t;

typedef struct database_options{
    uint64_t minimum_size;
} database_options_t;

typedef struct database_state db_state_t;

typedef struct database {
    db_state_t* state;
} database_t;


MUST_CHECK bool open_database(const char* path, database_options_t* options);
MUST_CHECK bool close_database(database_t* db);
```

The header in Listing 4.1 has a magic field, which must be set to the `FILE_HEADER_MAGIC` value. This is how we'll test if a file is a valid Gavran file or
something else. We already spoke about the `number_of_pages` and why we need it and the `version` field is future proofing. If we'll need to modify the 
layout of the data on disk, we can detect it from the header and react to it. The `page_size` is used to verify that we aren't attempting to open a file
whose page size is different from the `PAGE_SIZE` we are expecting.

The next question to ask is where are we going to place this information. The obvious answer is in the header, no? It is right there in the name. Let's see
what needs to be done to add this to our code. We need a higher level abstraction than the file, we need to now operate at the _database_ level, instead.
This is why we have the `database_options_t` and the `open_database` function. We are using the same `state` pointer trick as we did in the previous chapter, 
to allow us more freedom with how we are managing the internal state of our storage engine. 

In Listing 4.2, you can see what are the interesting details that we want to keep around as our state at the database level.

```{caption="The database state structure holds everything we need about a database" .c}
struct database_state{
    database_options_t options;
    file_header_t header;
    void* address;
    uint64_t address_size;
    file_handle_t* handle;
};
```

The `options` is fairly obvious. Right now we don't really have many options, but we will add to them and it make sense to store them where they are reachable.
The `header` we keep because we are going to need that quite often as we build the rest of our storage engine. The `address` is the `mmap`ed memory from the
file and the `address_size` is the size of the mapping. The `handle` data is stored immediately after the database state (and the filename past that) and we
can allocate the whole thing in one call. 

Before we get to actually opening the database, I want to look at how we'll _close_ it. The workhorse of Listing 4.3 is the `close_database_state` function.
This is called from `close_database` as well as `close_database_state_p` and takes care of tearing down the database we created properly. 
Why do we have dual entry points into closing down the database? The caller is expected to call `close_database` and we call `close_database_state_p` from 
a `defer` to handle failures in creating the database.

```{caption={Closing the database properly, accounting for partial construction} .c }
static MUST_CHECK bool close_database_state(db_state_t* state){
    if(!state)
        return true; // double close?
    bool result = true;
    if(state->address){
        if(unmap_file(state->address, state->address_size)){
            mark_error();
            result = false;
        }
    }
    if(state->handle){
        if(!close_file(state->handle)){
            mark_error();
            result = false;
        }
    }
    free(state);
    return result;
}

static void close_database_state_p(void* p){
    if(!close_database_state(p)){
        mark_error();
    }
}

bool close_database(database_t* db){
    if(!db->state)
        return true;// double close?
    bool result = close_database_state(db->state);
    db->state = 0;
    return result;
}
```

The first time that I wrote the `open_database` function, the amount of error handling was atrocious. We are coordinating resources around:

* Memory
* File
* Disk space allocation
* Memory mapped file
* Validation of the file format

Each one of them can fail and then we have to do the appropriate cleanup. I refactored said error handling into a `goto` based solution, but 
I still didn't like it. Then I realized that I can use the `defer` option to do the cleanup. Let's look at Listing 4.4 and see how that 
is done.

```{caption="Opening the database" .c}
static MUST_CHECK bool validate_options(
		database_options_t* options){

    if(options->minimum_size)
        option->minimum_size = 128*1024;

    if(option->minimum_size < 128*1024){
        push_error(EINVAL, 
        	"The minimum_size cannot be less than %d", 
        	128*1024)
        return false;
    }
        
    if(option->minimum_size % PAGE_SIZE) { 
        push_error(EINVAL, 
        		"The minimum size must be page aligned (%d)",
        		 PAGE_SIZE);
        return false;
    }

    return true;
}

bool open_database(const char* path, database_options_t* options, database_t* db){

    db_state_t* ptr = 0;
    // defer is called on the _pointer_ of
    // ptr, not its value;
    size_t* cancel;
    try_defer(close_database_state_p, &ptr, cancel);

    if(!validate_options(options)){
        mark_error();
        return false;
    }

    size_t db_state_size;
    if(!get_file_handle_size(path, &db_state_size)){
        mark_error();
        return false;
    }
    db_state_size += sizeof(db_state_t);

    ptr = calloc(1, db_state_size);
    if(!ptr){
        push_error(ENOMEM, 
            "Unable to allocate "
            "database state struct: %s", path);
        return false;
    }
    ptr->handle = (file_handle_t*)(ptr+1);

    if(!create_file(path, ptr->handle)){
        push_error(EIO, "Unable to create file for %s", path);
        return false;// cleanup via defer
    }

    ptr->options = *options;
    if(!ensure_file_minimum_size(ptr->handle,   
            options->minimum_size)){
        mark_error();
        return false;// cleanup via defer
    }
    if(!get_file_size(ptr->handle, &ptr->address_size)){
        mark_error();
        return false;// cleanup via defer
    }

    if(!map_file(ptr->handle, 0, 
            ptr->address_size, &ptr->address)){
       mark_error();
       return false;// cleanup via defer
    }
    
    if(!handle_newly_opened_database(ptr)){
        mark_error();
        return false;// cleanup via defer
    }

    db->state = ptr;
    *cancel = 1;// ensuring that defer won't clean it
    return true;
}

```

We first validate the passed `options`, then we start setting up the database. Creating the file, ensuring file size, mapping the memory, etc.
Each one of these actions may fail and require cleanup. I have used the `defer` macro previous to handle this situation, but now we have a 
different scenario. 

I don't want to unconditionally release those resources, I want to do that if the function was not successful. It it was successful, then I 
want no cleanup and to serve it to the caller. To handle that scenario, I defined a `try_defer` macro, which allows me to cancel the deferral
if needed. As you can see, we get a `cancelled` pointer that we can set to `1` in order to cancel the deferal. That allows me to have my 
cake in the sense that I don't have to use `goto` or write complex error handling code and still be able to cancel said behavior as needed.
Listing 4.5 shows the implemetnation of `try_defer`. 

```{caption="Setting a cancellable defer option allows for better error handling" .c}
struct cancel_defer {
   void* target;
   void(*action)(void*);
   size_t cancelled;
};

void _try_defer(struct cancel_defer* cd);

#define try_defer(func, var, cancelled_ptr) struct cancel_defer  \
   CONCAT(__defer__, __LINE__) __attribute__ \
   ((__cleanup__(_try_defer))) = {var, func, 0}; \
   cancelled_ptr = & CONCAT(__defer__, __LINE__).cancelled

void _try_defer(struct cancel_defer* cd) {
   if(cd->cancelled)
      return;
   cd->action(cd->target);
}
```

The was `try_defer` works in Listing 4.5 is similar to `defer`, relying on the `cleanup` property. However, instead of relying on the compiler
to call the function we route the call through the `_try_defer` function first. Where we are testing if the the user set the cancelled flag 
and we need to avoid calling the specified cleanup action.

After all this work, we can now open a database using the code in Listing 4.6. I think you'll agree that this is much nicer API to present to
our users. 

```{caption="Opening a database using the new API" .c}
database_options_t options = {0};
database_t db;
if(!open_database("db/orev", &options, &db)){
  print_all_errors();
  return EIO;
}

```

The `open_database` function in Listing 4.5 contains a new function that we didn't cover: `handle_newly_opened_database`. All the work that was
done in `open_database` was just setup. Opening the file, getting the memory map, etc. We _still_ haven't done anything to the file and we 
still have no header.

Listing 4.7 fix all those issues and show how our storage engine opens a file. 

```{caption="Starting up a database by reading the metadata or setting it up" .c}
static MUST_CHECK bool handle_newly_opened_database(database_t* db){

    db_state_t* state = db->state;
    file_header_t* header1 = state->address;
    file_header_t* header2 = 
    	(void*)((char*)state->address + PAGE_SIZE/2);
    
    // at this point state->header is zeroed
    // if both headers are zeroed, we are probably 
    // dealing with a new database
    bool isNew = 
    	!memcmp(header1, &state->header, sizeof(file_header_t)) && 
        !memcmp(header2, &state->header, sizeof(file_header_t));

    if(isNew) {
        // now needs to set it up
        state->header.magic = FILE_HEADER_MAGIC;
        state->header.version = 1;
        state->header.page_size = PAGE_SIZE;
        state->header.number_of_pages = 
        	state->address_size / PAGE_SIZE;
        if(!set_file_headers(state)){
            mark_error();
            return false;
        }
    }
    file_header_t* selected = 
    	header1->magic != FILE_HEADER_MAGIC ? 
    		header2: header1;
    if (selected->magic != FILE_HEADER_MAGIC) {
        push_error(EINVAL, 
        		"Unable to find matching header in"
        		" first page of %s", 
        		get_file_name(state->handle));
        return false;
    }
    if(selected->number_of_pages * PAGE_SIZE > 
    		state->address_size){
        push_error(EINVAL, 
        	"The size of the file %s is %lu but"
        	" expected to have %lu pages, file "
        	"was probably truncated", 
            get_file_name(state->handle), 
            state->address_size, 
            selected->number_of_pages * PAGE_SIZE);
        return false;
    }
    if(selected->page_size != PAGE_SIZE){
        push_error(EINVAL, 
        	"File %s page size is %d, expected %d", 
            get_file_name(state->handle), 
            selected->page_size,
            PAGE_SIZE );
        return false;
    }

    return true;
}
```

The first thing we do in `handle_newly_opened_database` is to get the first page of the file and look at two locations in it. You can look at Figure 4.1 
to see a diagram of how the data is expected to be laid on on the file. The idea is that in the first page, we are going to store the header _twice_, 
once at the start of the file (position 0) and once at the midway of the page (position 4096). 

![Physical layout of the header records in the first page](./ch04/img01.png)

Why are we storing the header data twice? Note that we are spreading the data 4KB apart, which is the size of a block. The idea is that we are going to 
have a backup copy of the file header if we had an incomplete write or a failure. This is just the first of _many_ preventive steps that we are going to 
take. 

Because we test both locations, we will determine if the file is new if the first page is full of zeroes. A newly allocated file is always going to be filled
with zeroes, so we need to setup the file header for the first time and write it back to disk. Listing 4.8 has the deatils on how that is done.

If the file isn't new, we select one of the headers and test it. We check that the file has the right version and page size that we expect as well as
well as the right first 8 bytes signature. If all validation pass, we are good to go.

```{caption="Updating the file header" .c}
static MUST_CHECK bool set_file_headers(database_t * db){
    txn_t tx;
    if(!create_transaction(db, 0, &tx)){
        push_error(EINVAL, "Failed to create a transaction"
        	" on database init: %s", 
        	get_file_name(db->state->handle));
        return false;
    }
    defer(close_transaction_p, &tx);
    page_t page = {0, 0};
    if(!modify_page(&tx, &page)){
        push_error(EINVAL, "Unable to get first"
        	" page of file: %s", 
        	get_file_name(db->state->handle));
        return false;
    }
    memcpy(page.address, 
    		&db->state->header, sizeof(file_header_t));
    memcpy((char*)page.address + PAGE_SIZE/2, 
    		&db->state->header, sizeof(file_header_t));

    if(!commit_transaction(&tx)){
        push_error(EINVAL, 
        	"Unable to commit init transaction on: %s",
        	get_file_name(db->state->handle));
        return false;
    }

    return true;
}
```

Listing 4.8 is the first time that _we_ are actually starting to use our own API to implement real functionality. As part of starting up the database
we'll create a transaction, modify the first page so we can write the headers and commit to the file. 

## Managing free pages

Now that we have all of this setup properly, the question _why_ raises itself. We wanted to implement `free_page` and `allocate_page`, how does this 
help us? The answer is that in order to write those functions, we need to have a place to store metadata about the file. We now have a place to do this
setup: `handle_newly_opened_database` and a method to do that, using our transaction API.

The next step is deciding exactly how we'll implement the free list. I want to build up in complexity, so any complex data structure is going to be hard
to build. The easiest way to manage the free space is to use a bitmap or a bit array for the free/in used marker.

Let's run some numbers and see how feasible this is? Let's assume we have a file that is 512GB in size, using 8KB pages, that gives us 
`67,108,864` pages to keep track of. In order to manage that using a bitmap, you'll `8,388,608` bytes which is exactly 8MB. In other words using a bitmap
to store the free/busy mode means that we will use 1/65,536 of the data for the free list. That means that about 0.0015% of the disk space will be dedicated for
this purpose.

The bitmap approach has several advantages:

* Simple to implement and obvious how to get working.
* Negligble amount of space overhead.
* There are many ways to efficeintly search a bitmap.
* There is a fixed size for the free list, we don't need to handle alloc / decalloc of space except when we grow the actual file.

This hits all the sweat spots, so let consider how we can go about implementing this? If you'll recall Figure 4.1, we are using the first page of the file 
as the location of the headers. Where would we put the free space bitmap?

As easy solution would be to place it as the second page, but that has an issue, how are we going to handle growing the file? A single page will give us
enough bits to manage a free list of a file up to 512MB. But what would you do next? You would need more space and it is best if we kept the free list
bitmap as a single consecutive buffer. 

The answer is that we are going to manage this process _using_ the free list itself. One of the responsabilities of the `handle_newly_opened_database`
will be to setup the initial free list bitmap. Following this, when we need to increase the free list size, we'll ask the free list itself where we
can place the increased list size and then free the old location.

Simple, at least as a concept. Let's see what will happen when we sit down to actually implement this...