== Managing disk space allocations

In the previous chapter, we built up the transaction API and were able to modify a page and persist it back. At this point, the code we have makes absolutely no 
assumptions about the data we have on disk. We operate on the data in page units and blindly. This cannot go on, because we can't expect the users to know how to 
manage the pages and their content by themselves.
We need to be able to allocate and free pages. Once we have that, we can build more sophisticated data structures. 
The new API we want to have are shown in <<tx_allocation>>.

[source]
[[tx_allocation]]
.`gavran/db.h` - The new transaction API that we will to implement
----
include::../include/gavran/db.h[tags=tx_allocation]
----

Let consider what we actually need to do in order to implement the ability to dynamically allocate and free pages. We need to persist somewhere that pages are taken or free. 
We need to be able to search for a free page and we need to be able to mark a page as free. That means that we are going to store that information in the file itself. And that lead
to a bunch of questions. How are we going to do this? What would be the format of the data? How well will it play with future features?

We want to create a system that will serve for the foreseeable future, we want to ensure that it plays nicely with the API we created so far and that is doesn't
require complex implementation. We are too low in the stack yet to be able to do truly interesting things. The whole point of this book is to build the features
one on top of the other. 

=== The file header

Looking at the API above and how we can implement them, I think we'll the following information:

* The size of the file in pages - we need to store that information inside the data file because relying on the size of the file as reported by the operating
  system cannot serve us for long. If we failed after the file size was extended but didn't update our internal metadata, we'll probably not enjoy the result.
* A way to tell if a page is free or in used.

Right now we need to keep track of only one piece of data about the file, its size in pages, but I'm sure that we'll have more in the future. To handle that
we'll create the following structure to serve as the header for the file and be the metadata location. You can see what this will look like in <<file_header>>.

The header in <<file_header>> has a `magic` field, which must be set to the `FILE_HEADER_MAGIC` value. This is how we'll test if a file is a valid Gavran file or
something else. We already spoke about the `number_of_pages` and why we need it and the `version` field is future proofing. If we'll need to modify the 
layout of the data on disk, we can detect it from the header and react to it. 
We are going to ignore the `last_tx_id` in this chapter, and we'll get to `free_space_bitmap_start` later in this chapter.

The `page_size_power_of_two` is used to verify that we aren't attempting to open a file whose page size is different from the `PAGE_SIZE` we are expecting.
We use the power of two mode because we want to reduce the number of bytes that we are using as much as possible. This is a _persistent_ structure, which will be
stored on the disk. As such, we are going to start caring quite deeply about how big certain things are.

[source]
[[file_header]]
.`gavran/db.h` - The file header contains metadata about the whole file
----
include::../include/gavran/db.h[tags=file_header]
----

The next question to ask is where are we going to place this information. The obvious answer is in the header, no? It is right there in the name. Let's see
what needs to be done to add this to our code. We need a higher level abstraction than the file, we need to now operate at the _database_ level, instead.

This is why we have the `db_options_t` and the `db_create` function, which we saw in the previous chapter. In the last chapter, `db_create` would open a database
by validating its options, setting the size and creating the memory mapping. I mentioned there that we'll do more work in `db_init()` in the future.
Well, the future has arrived, and now is the time to put some structure in our file. Take a look at <<file-header>>, which shows how where we'll put the data in 
the file. 

[[file-header]]
.The physical layout of the header records in the first few page in the file
image::file-header.png[]

In the last chapter, we saw that `db_create()` will ask the file system to allocate disk space for the file ahead of time, which will always be zero filled. In order
to check if the file is new or not, we can check the `page_flags` value on the first page. If the value is set to zero, we can assume that this is a new file and 
set it up accordingly. 

Note that this isn't really a good idea in general. A single flipped byte may cause us to mistake a valid file as new and initialize it as an empty file. We'll do
much better later on. In fact, you'll start to see some hints on how we are about to approach this task from this chapter. For now, we'll assume that checking the 
`page_flags` value on the first page is sufficient. 
The actual work is managed by the `db_init()`, which is called after `db_create()` setup the file, wired the memory map, etc. 

[TIP]
.Duplicating data for safety reasons
====
In many low level formats, you will often see intentionally duplicated data. You'll have the file metadata at the beginning and the end of the file. 
NTFS, for example, will write its MFT (Master File Table) at the start of the disk as well as the middle. The idea is that if there is something wrong in 
the disk, there is another location to search for the data.

I decide to avoid doing this in Gavran, for several reasons:

* Old disks used to have platters and sectors and such. Almost all new disks will be SSDs based and use a very different format internally. In particular, 
it is very common for SSD systems to coalesce writes that happened at the same time into the same block, even if they are meant to be far apart in the disk.
That renders attempts to keep a piece of data in sync in multiple locations for safety reasons mostly useless.
* It adds complexity and time. Even if the actual work isn't too hard, to make use of it, there is the need to write recovery code that would make use of 
a potentially corrupted file. I have done this for the Voron files, and it isn't much fun. 
* In many cases, this is already handled by lower layers, either at the file system or the drive layer.
====

In <<db_init>> you can see that we first check if the file represent a new database or an existing one. The `db_is_new_file()` is a really interesting function
because it uses the _transaction_ API to do its work. Why is that remarkable in any way, though?

Remember, at this point, we have to assume that we may be operating on:

* A valid Gavran data file, created by a previous run on Gavran.
* A zero filled file that was allocated by `db_create()` and which we'll need to setup properly.
* A file with data that isn't a valid Gavran file. That can be:
** A corrupted Gavran file (bug, disk error, etc).
** A file that isn't even a Gavran file, may be a zip file, a PNG, etc.
** A malicious file that came from a non-trusted source. 

That is why the `txn_raw_get_page()` and `txn_raw_modify_page()` are considered _raw_ API, they can make no assumption on the data that they operate on. The check
in `db_is_new_file()` isn't actually a check on a single byte, instead we check that the whole `page_metadata_t` is set to zero. We'll discuss what exactly that is 
in just a little bit. If the first `page_metadata_t` is zeroed, we consider the file to be new and will call to `db_init_file_structure()` to perform the actual
initialization.

Regardless of whatever the file is new or not, we'll validate its structure and initialize our in memory state from the file in `db_init_from_existing_file()`. 
That adds another layer of validation to protect us from bugs or disk issues.

[source]
[[db_init]]
.`db..c` - Checking if the database already exists or is new and then setting it up
----
include::./code/db..c[tags=db_init]
----

Now that we understand how Gavran knows whatever the file is new or not, let's look at how we are going to go about initializing the file startup.
You can see the behavior in <<db_init_file_structure>>, the code there is interesting for a very important reason. It is using a _transaction_ to modify the data. 
This is strange, because transactions right now aren't really that fancy. Why wouldn't we write to the data directly using `pages_write()` or `pal_write_file()`?
The reason is that we want Gavran to be a transactional storage engine. 

That means that _all_ the writes to the system must be durable and that means that we can't sneak _any_ writes to
the file under the radar. Our transactions will make sure that the data changes are valid, and they are the only way to write to the file. 

<<db_init_file_structure>> is the also first time that _Gavran_ is actually starting to use its own API to implement real functionality. As part of starting up the database
we'll create a transaction, modify the first page so we can write the headers and commit to the file. That is cool!

Another interesting thing about the `db_init_file_header()` function is that it neither _creates_ a transaction not _commits_ it, that is actually handled by `db_init_file_structure()`
because we need to coordinate a bit more than just setting of the header. Before we can get to that, though, we need to talk about another interesting aspect of `db_init_file_header()`.
We aren't manipulating directly, instead, we go through data structures to modify the data in memory and then persist that data to disk. 

[source]
[[db_init_file_structure]]
.`db..c` - Initializing the file on startup
----
include::./code/db..c[tags=db_init_file_structure]
----

We already saw how `file_header_t` looks like in <<file_header>>, we should also look at the `page_metadata_t` structure, shown in <<page_metadata_t>>, to complete the full picture. 
This is a _persistent_ data structure, in the sense that we are going to write it to disk and use it quite often. As such, there are a number of of things that we should discuss about 
this critical structure.

The `page_metadata_t` is exactly 64 bytes in size. The first 32 bytes of the structure are taken by a `crypto` header. I'm going to spend the whole of Chapter 11 to discuss that, so 
we'll skip this for now. The rest of `page_metadata_t` is a union of the structures that may be part of the page metadata. We use the `page_metadata_common_t`, which define the 
`page_flags` field to check what is the actual type of the page and then we can switch to the right union member and work with it directly. All the structures in the union _must_
have `page_flags` as their first field and be up to 32 bytes in size.

[NOTE]
.What about alignment?
====
One of the dangers of casting between pointers between different structures is that we'll hit undefined behavior. In this case, we got it covered because we are using a union
and making sure that the initial field match across all of the types that will be stored in the `page_metadata_t`. 
====

[source]
[[page_metadata_t]]
.`gavran/db.h` - The page metadata structure 
----
include::../include/gavran/db.h[tags=page_metadata_t]
----

[TIP]
.Why all the small functions?
====
You might have noticed that I'm using very small functions in the code. There are three reasons for this decision:

* Shorter functions tend to be more readable and the using `defer` and `ensure` means that I don't have so much visible plumbing.
* I need to fit these functions into a book format, which means that I have a hard limit on how much code I can show on a single page. Aside from the unit tests, I want to avoid multi page
  code listing. They are rather daunting and make it hard to explain exactly what is going on in the engine.
* Small functions means that I can update a single function's behavior and then show what changed there, without having to provide too much additional context. Here is the new version of
  `do_something_small()` is so much better than trying to push a diff of a longer function, in terms of readability.
====


[source]
[[db_init_from_existing_file]]
.`db..c` - Validating the file on startup
----
include::./code/db..c[tags=db_init_from_existing_file]
----

Now that we understand how we structure (pun intended) the data on disk, let's see how we are actually making use of it. The database initialization is done on <<db_init_from_existing_file>>.
Although it might be a stretch to call it initialization at this point. Right now the only thing that we are going to do is to validate the on disk data. 

[source]
[[db_validate_file_header]]
.`db..c` - Validating the file header
----
include::./code/db..c[tags=db_validate_file_header]
----

We start by creating a transaction, remember that we can't read or modify any data from the file without a transaction. That is _important_. I know that I have talked about this previously
but it is well worth repeating. By making sure that there are no cheats, we are going to create a robust system. Using the read transaction we create, we access the first page and verify
that it is setup to be a file header page. We then validate that the header is valid in <<db_validate_file_header>>.

In `db_validate_file_header()` we validate that the header match our expectation. The `page_size` and `version` are as expected and that we have the magic value in the right place. Note that
because the `page_metadata_t` has a `crypto` for its first 32 bytes, the actual `magic` field is located on bytes 36 - 41. That is not typically where you'll put the string identifying your
file. Usually that is the very first bytes of the file. I'm doing it this way to make it (much) easier for me when we get to Chapter 11 and talk about the `crypto` part of the page metadata.

=== Allocating and freeing pages

Now that we have all of this setup properly, the question _why_ raises itself. We want to implement `txn_free_page()` and `txn_allocate_page()`, how does this 
help us? The answer is that in order to write those functions, we need to have a place to store metadata about the file. We now have a place to do this
setup: `db_init_file_structure()`.

The next step is deciding exactly how we'll implement the free list. I want to reduce complexity as much as possible, so any complex data structure is going to be hard
to build at this point, without much infrastructure in place. The easiest way to manage the free space is to use a bitmap or a bit array for the free/in used marker.

Let's run some numbers and see how feasible this is? Let's assume we have a file that is 512GB in size, using 8KB pages, that gives us 
`67,108,864` pages to keep track of. In order to manage that using a bitmap, you'll `8,388,608` bytes which is exactly 8MB. In other words using a bitmap
to store the free/busy mode means that we will use 1/65,536 of the data for the free list. That means that about 0.0015% of the disk space will be dedicated for
this purpose.

The bitmap approach has several advantages:

* Simple to implement and obvious how to get working.
* Negligible amount of space overhead.
* There are many ways to efficiently search a bitmap.
* There is a fixed size for the free list, we don't need to handle allocate / free of space except when we grow the actual file.

This hits all the sweat spots, so let consider how we can go about implementing this? If you'll recall <<file-header>>, we are using the first page of the file 
as the location of the headers. Where would we put the free space bitmap?

As easy solution would be to place it as the second page, but that has an issue, how are we going to handle growing the file? A single page will give us
enough bits to manage a free list of a file up to 512MB. But what would you do next? You would need more space and it is best if we kept the free list
bitmap as a single consecutive buffer. 

The answer is that we are going to manage this process _using_ the free list itself. One of the responsibilities of the `db_init_file_structure()`
will be to setup the initial free list bitmap. Following this, when we need to increase the free list size, we'll ask the free list itself where we
can place the increased list size and then free the old location.

Simple, at least as a concept. Let's see what will happen when we sit down to actually implement this... the full details are in <<db_init_free_space>>.

[source]
[[db_init_free_space]]
.`db..c` - Creating the initial free space bitmap
----
include::./code/db..c[tags=db_init_free_space]
----

Similarity to `db_init_file_header()`, we are starting with using the transaction to get the first header page and grab the `number_of_pages` from the 
file header (which was previously set up in `db_init_file_header()`, which is called before `db_init_free_space()`). We setup the free space bitmap
as the _second_ page, and register it in the metadata of the second entry in the first page on the file. This will become much clearer when we'll discuss
how we handle pages metadata later on in the next chapter.

We compute how many pages we'll need for the free space bitmap using `ROUND_UP` and `BITS_IN_PAGE`. A page is 8KB, so we have a total of `65,536` bits in
a page and the bitmap can handle 512MB of pages. Note that we store the page number where the free space bitmap in the file header, inside
`free_space_bitmap_start`. Initially, this is hard coded to the second page, but as we discuss, we may need to move it as the file size grow, and that field
will always let us know where to find it.

We use `txn_raw_modify_page()` to get the page's buffer. Note that we pass a `size` value to `txn_raw_modify_page()`. This is used when we need to modify
multiple pages as a single buffer. The next step is to simply mark the busy pages in the file at this point. The first few pages are marked as busy, those
are the header page and the pages used by the free space bitmap itself. In most cases, when we initialize a file, the size will be less than 512MB and we'll
use just a single free space bitmap page. I don't like placing arbitrary limits on my code, so I'm handling initialization with any size of the file.

We also mark the pages in the _end_ as busy. Why is that? The free space bitmap operates in pages of 8KB, each of which contains 64K bits. If the size of the 
file does not align on a 512MB boundary, we are bound to have more entries in the free space bitmap than we have pages in the file. We handle this scenario by
simply marking the pages beyond the end of the file as busy. We'll need to address that when we'll allow to increase the file size.

Using a bitmap for the free space management is simple and effective. It cuts down on the complexity of the system. LMDB, for example, uses its own
data structure (B+Tree) to manage the free list. That can lead to recursion where the free list needs to allocate or free a page while a free 
list operation is ongoing. That can lead to... issues and took a while to properly stabilize. This model, however, solve all those issues very
neatly.

.Low level transaction API
****
Using the transaction API to manage the startup of our database is cool, but it comes at a cost. We are using the API at a time when we haven't actually
done the setup. That means that there might be invariants that are broken. What _that_ means is that the APIs that we are using 
(`tx_create()`, `tx_raw_modify_page()` and `tx_commit()`) are going to have to be able to work with no setup at all from the rest of the system.

We need to be careful during initialization and many other functions that operate of transactions may not work at this point. For example, we cannot call
`txn_allocate_page()`, because the free space bitmap that would tell us _where_ to allocate the page hasn't been setup yet.
****

If you'll look at the code in `db_init_free_space()`, we even handle cases where recording the pages of the free list itself as busy will take
more than one page. That can only happen once the database exceeded 4TB in size. Not something that I expect to be common, but it doesn't take a lot
of code to handle this. We also used the `set_bit()` utility functions in <<db_init_free_space>>, you can see all the bit manipulations function in
<<bit-manipulations>>. 

As you can see in <<file-layout-with-freepsace>>, the second page is used for the free list and the first two bits there are marked as busy. The rest of the page is 
filled with zeros, indicating free pages. Where did those zeros come from, however? We didn't set them up.
These zeros are there because we create a new file. Even though we preallocated the size of the file, the operating system ensures that the 
contents of the file are zeroed. Otherwise, you may get sensitive data from other files. We rely on this property here to avoid doing extra work.

[source]
[[bit-manipulations]]
.`gavran/db.h` - The page metadata structure 
----
include::../include/gavran/db.h[tags=bit-manipulations]
----

[[file-layout-with-freepsace]]
.Layout of the file on disk after adding the free space bitmap
image::file-layout-with-freepsace.png[]

=== Freeing a page

The act of freeing a page is a lot easier than allocating one using this model. That is typically _not_ the case, so this feature of the system
architecture makes me very happy. Let's look at <<txn_free_page>> to see how this is done.

[TIP]
.Designing for the underlying system
====
We haven't touched on this much yet, but one of the core design principles that I keep in mind while build Gavran is that I want to work _with_
the systems I'm using. That means understanding how hardware, processors, memory and operating systems are built and what patterns they seek
to optimize.

If we intentionally build Gavran to have patterns that the underlying software and hardware is already setup to speed up, we are going to get
amazing benefits, with very little apparent work. A lot of thought has gone into how to structure things so you don't _need_ to write a lot
of code to get the desired functionality.

I already talked about this behavior with regards to memory mapped I/O and leaning on the operating system's page cache as a good example of this
practice. Another example is the use of pages to work with the data, that is how the operating system, the RAM and the disk work and matching that
behavior means that we don't have to deal with issues such as torn writes, read-modify-write costs, etc.
====

[source]
[[txn_free_page]]
.`txn.alloc..c` - Freeing a page in a transaction
----
include::./code/txn.alloc..c[tags=txn_free_page]
----

The fact that there is so little to do here is quite impressive. Even I'm saying this about my own code.
The `txn_free_page()` in <<txn_free_page>> is getting the page that we want to free and zero it as its first action. I'm doing that for the following reasons:

* Ensure that if you try to access a page that was freed, you'll know about it straight away. More paranoid approach would be to physically `unmap()` the 
  page, ensuring that any access will result in a seg fault, but that is probably too much.
* Scrub away the data the user indicated the they want to delete. This isn't really a security feature, mind. You'll usually work at a level
  smaller than a page anyway...
* https://devblogs.microsoft.com/oldnewthing/20161109-00/?p=94675[Zero page optimization] at the operating system level.
* Enable us to use other optimizations down the line, because we can recognize zero filled pages.

Note that aside from zeroing the page, we don't do anything special with it. Given that we set it in the free space bitmap, it may be used again if
the transaction will allocate a new page. The only thing that matters is that the page is modified and will be written to disk. This bears repeating. A freed
page gets absolutely no special treatment. It is just another way to modify a page.

We also modify the bitmap to record that the page (or pages, if it spans multiple pages) is now free. We do that in a way that is blind to the fact that this is a free space page. We 
simply apply the changes to the free space bitmap on a modified page that will be written to disk. So we don't actually _need_ to do anything special here. I'm really happy with 
how this turned out.

=== Building an allocation strategy

Memory allocation (and this is what the `txn_allocate_page()` is all about) is a complex topic. There have been papers, books and dissertations written about
the topic. The oldest reference that I could find for a memory allocation algorithm is from _1963_. The latest I could find was this week, I'm pretty sure
that if you flex your Google muscles, you'll be able to find one posted today. For whatever value of today you feel like choosing.

There are https://conf.researchr.org/track/ismm-2020/ismm-2020[_conferences_ about memory management]. Just memory management, a whole conference. With 
annual events that started in _1992_ (and I didn't search hard). 

I'll let that sink in for a while, because we have been doing that for over half a century and this is still a hot area of research. 
I'm not going to try to win prizes with the allocation strategy I'm going to outline here, but at the same time, the _reason_ that this is such a hot topic
is that this is a critical piece of functionality. 

A good allocator should be fast to execute, of course, but it also has a host of other properties that we need to consider. Among them we have:

* Increased locality of reference. Having related data sit physically close can be a major performance boost.
* Reduce fragmentation. Right now, we only request a single page at a time, so that is not an issue. We need to be prepared for when we'll need to deal with
  multi page allocations. In that case, we want to avoid internal fragmentation as much as possible.

We already know that the backing store of the allocation is the free space bitmap. A busy page is marked with `1` and a free with `0`. In essence, the allocator
needs to be able to find the position of a zero bit in the bitmap. The good news is that this is very cheap operation, usually. The bad news is that we need
to be able to answer the question not on a single bit but on a range as well.

The basis for my code is from https://lemire.me/blog/2018/02/21/iterating-over-set-bits-quickly/[Daniel Lemire's work], adapted to allow us to find a range
of values. We start from the declarations in <<bitmap_search_decl>>.

This function accepts the `bitmap_search_state_t` with the bitmap buffer and its size, the required size and the preferred location and returns the found position using the `found_position`
output value. As usual, we use the return value to indicate success or failure only. In this case, the function does no allocation and a failure here means that we couldn't find a free range 
to satisfy the required space.

We might also find _more_ space than was asked for, so we report that to the caller so they can make an informed decision about what to do with the extra space. 

The `bitmap_search_state_t` is a complex structure, meant for internal consumption only. The caller should zero initialize the structure except for the `input` nested structure. Then the
`bitmap_search()` will find a free range in the bitmap. It is a pretty complex piece of code, composed of multiple layers. I'm going to explain it from the bottom up. 
Starting with the most basic step in the process, the `bitmap_search_word()` function. <<bitmap_search_word>> shows how `bitmap_search_word()` works.

[source]
[[bitmap_search_decl]]
.`gavran/internal.h` - Declarations to find free space range in bitmap
----
include::../include/gavran/internal.h[tags=bitmap_search]
----

The `bitmap_search_word()` operates on a _single_ word (`uint64_t`). Each time it is called, it will go through up to 64 bits (thus, 64 pages or 512KB) to
find the next free range. If the entire word is set (all busy), we'll return `false` and have the caller provide us with the next word to search.
If the entire word is zero, we will check if the current available space plus whatever we have from previous words is enough to satisfy the requested space.
This is done in the `bitmap_finalize_match()` function, shown in <<bitmap_finalize_match>>.

The most interesting part in <<bitmap_search_word>> is when we have a word that has a mix of set and cleared bits. Then we need to find if there are enough cleared consecutive bits 
_inside_ the word. We use the technique describe by Lemire to do so. 

We measure this using `{ctlz}` which is an operation that would count the trailing zeros on the value. We use that to compute the distance to the first set bit, 
check whatever that gives us the right range or not. If we didn't find the right range, we then clear the least significant bit using: `(x & -x)`. This will
keep just the least significant bit in the number, and we then clear that from the current value. That allows us to count the distance to the set bit and then 
remove that set bit and count again. We use that distance as a way to know where the cleared ranges are. To handle the case of the first bit being clear, 
we also have an _intentional_ overflow of the `previous_set_bit` field (unsigned value, so no undefined behavior here). 

[source]
[[bitmap_search_word]]
.`bitmap.c` - Finding a range of free bits inside a single word
----
include::./code/bitmap.c[tags=bitmap_search_word]
----

:ctlz: __builtin_ctzl

Finally, we call `bitmap_finalize_match()`, in one of two cases. If the entire word is zeroed or if we run through all the set bits and now we have a free range at the
end of the value.  We rely on `previous_set_bit` to be set to `ULONG_MAX` by the caller of `bitmap_search_word()` and then add one to it. If there have been no other set bits, 
the value overflow and is set to 0, which is then used as the starting point of the current range. If there is a value in `previous_set_bit`, we move one
past the last filled bit and return that. 

This code is succinct, and I like how it turned out. It took several tries to get something that works and was maintainable 
A part of what make this function challenging is that we are keeping track of the state _across_ calls. For example, we may have a free range that strides a
word boundary. That will be handle in _two_ calls to `bitmap_search_word()`. 

[source]
[[bitmap_finalize_match]]
.`bitmap.c` - Validating a potential range match
----
include::./code/bitmap.c[tags=bitmap_finalize_match]
----

It might be easier to understand if you take a peek at <<bitmap-colored>>, which shows a bitmap in a visual manner for the bitmap:
 `{0x80520A27102E21, 0xE0000E00020, 0x1A40027F025802C8, 0xEE6ACAE56C6C3DCC}`. 

[[bitmap-colored]]
.Visualization of the bitmap 0x80520A27102E21, 0xE0000E00020, 0x1A40027F025802C8, 0xEE6ACAE56C6C3DCC
image::bitmap-colored.png[]

<<bitmap-colored>> has three types of cells:

* Marked with `X` - busy. 
* Marked with `V` and colored - we'll run a few sample queries on them, so I highlighted them for ease of identification.
* Empty - free cells. 

Look at the first row of cells in <<bitmap-colored>>, if we want to allocate a page near the marked position (red), where would you put it? What if we wanted to 
allocate two pages? In the middle of the image, there is another marked position (yellow), I want to get 4 pages near that location. And we want to get
7 pages near the last marked position (green). 

The data in <<bitmap-colored>> has multiple words to go through, let's see how the code is handling it. We use the `bitmap_search_word()` to search a single word and 
`bitmap_search_once()` to search the entire bitmap. The code for that function in in <<bitmap_search_once>>.


[IMPORTANT]
.Why are we spending so much time with the allocator?
====
It may seems strange that I'm covering so much time right now for the implementation of the allocator. I just checked how it goes with Voron, RavenDB's storage
engine, and I found that the last time anyone made a meaningful change there was in Oct of 2015 and most of the actual work was done in 2013. It has been
able to handle production loads for all this time without us really needing to pay it much attention.

However, it took _time_ and a lot of hard work to get there. In Gavran, I'm trying to avoid that complexity pitfall by doing things properly from the get go.
I'm writing this in Jun of 2020, which means that five to eight years after the fact, I still remember how hard getting free space handling in Voron was to
get _right_.
====

[source]
[[bitmap_search_once]]
.`bitmap.c` - Finding a range of free bits in the entire bitmap
----
include::./code/bitmap.c[tags=bitmap_search_once]
----

Because most of the work is done by `bitmap_search_word()`, the code for `bitmap_search_once()` mostly deals with orchestrating it. We try to find a range in the current word, 
and if we can, we mask it so the next call will _not_ find it. That is the core of how we iterate. If we run out of the current word, we'll switch to the next one and 
continue the search. Note that even if we found an appropriately sized range, if it is in the end of the current word, we'll scan the next word at least
to find what the _size_ of that range is. 

We could use `bitmap_search_once()` to manage the task of allocating the next range, but that wouldn't be ideal. Finding the first free range that fit our needs
is an allocations strategy that is called First Fit. I looked it up and here are 
https://dl.acm.org/doi/pdf/10.1145/359436.359453[couple of papers from _1974_] that discusses 
https://www.researchgate.net/publication/220459885_Worst_Case_Fragmentation_of_First_Fit_and_Best_Fit_Storage_Allocation_Strategies[its usefulness].
They are mostly here as a historical interest, they are testing this out on a PDP-11.

The core issue with first fit is that it can cause internal fragmentation. In other words, we allocate pages in such a pattern that even though we have the
the right number of pages free, we don't have enough _consecutive_ pages to answer the allocation. We can do better. The key to that is shown in <<bitmap_search_smallest_nearby>>.
 For such a short function there is a _lot_ of functionality there.

[source]
[[bitmap_search_smallest_nearby]]
.`bitmap.c` - Finding the _best_ free range for an allocation
----
include::./code/bitmap.c[tags=bitmap_search_smallest_nearby]
----

What `bitmap_search_smallest_nearby()` does is to use `bitmap_search_once()` in a loop, trying to find the best match. In this case, we define best as the smallest
range that can fit the requested size. However, we also take locality of reference into account here. The code will try to find a range that starts
within roughly 64 pages (512Kb) from the requested position. If we can't find such a range, we'll try to either use a larger than necessary range from near
the requested location or the first suitable range of any size that we run into.

[TIP]
.Worst case performance
====
What is the worst case for this function? If the entire bitmap is full and there is no free space, or if there are no free spaces large enough for
the required allocation. The cost of that is iterating over the bitmap memory. For a 512GB database, that will require us to scan a bitmap of 8MB. 
That isn't going to break the bank, especially since the bitmap is a single run that we can scan through and the system will optimize this for us
automatically.

There are ways that to optimize this, we can remember where was the last location that we were able to find a free range, for example. As usual, further
performance optimizations will remain unimplemented unless a benchmark convince me otherwise.
====

We can now look at `bitmap_search()` itself and see how it works, take a look at <<bitmap_search>>.

[source]
[[bitmap_search]]
.`bitmap.c` - Allocate a range from the bitmap
----
include::./code/bitmap.c[tags=bitmap_search]
----

We call `bitmap_search_smallest_nearby()` from `bitmap_search()` with range that starts at the current location. In other words, we are skipping
looking at the pages that come before the requested location. We'll look there only if we couldn't find a range afterward. This is important because
it bias the allocations forward.

That is an intentional design decision. The idea is that you'll call `bitmap_search()` with the location of an item you already have and
ask it to be placed nearby. As you'll likely do that over a wide range of locations, that should balance things out. You can also pass `0` as the 
starting location, in which case we'll search for the _best_ fit in the entire bitmap, ignoring the location sensitive brake.

=== Allocating pages

Now that we have an allocator ready, let see what it takes to actually allocate a page, shall we? Without further ado, skip ahead to Listing 5.12 to
see how it all comes together.

[source]
.Listing 5.12 - txn.c - Allocate a page in the transaction
----
include::./code/txn.alloc.c[tags=txn_allocate_page]
----
<1> This utility function is used to mark a page as busy in the free space bitmap.
<2> Right now we deal with all pages as single units. We cannot search across free space pages. We'll be fixing this later.
<3> Here we run the actual search.
<4> When we find an available page, we zero it (just to be on the safe side) mark it as busy in the bitmap and return.
<5> Handling the case of no space left on the file. 

We are scanning through the free space bitmap, one page at a time, trying to find a free page. When we find the page, we call `txn_modify_page` on it. We then
zero it. This isn't something that we _have_ to do, we already zero pages when we free them and we know that we are getting zeroed pages from the file 
system. I'm doing this to make doubly sure that we don't end up with strange things in here. The rule is that if you asked for a new page, you'll get it
free and clear.

Now, I need to mark the newly allocated page as busy. Note that I _cannot_ just use `bitmap_page` here, I got that through `txn_get_page`, which returns a 
read only copy. I need to call `txn_modify_page` on the page and then work with he _new_ address that we get. After that, it is just an issue of setting the
right bit and completing the operation successfully.

As it currently stand, the `txn_allocate_page` will fail once we have run out of the internally allocated space. We'll need to address that, we want to allow
the user to increase the file size as needed. We'll deal with this issue as well in the next chapter.

=== Putting it all together

This chapter has gone on longer than I expected, but we are finally here. You can look at Listing 4.18 to see how we can use the new API. I decided to skip
the error handling here, since this is just concept code. It makes the intent much more readable.

[source]
.Listing 5.13 - main.c - Using the transaction allocation API
----
include::./code/main.c[tags=allocate_page_and_use_it]
----
<1> Create the database (and set close on function end via `defer`).
<2> Create a transaction (and close via `defer`).
<3> Allocate a new page using the free space bitmap
<4> Copy data to the new page
<5> Commit and close the transaction
<6> Create a new transaction to read the data. Note that _this_ transaction will be closed via the previous setup `defer`.

The code in Listing 5.13 will print the new allocated page number (2) and the string "Hello Gavran". 
You can run this multiple times to see how it allocates a new page on each run. Calls to `txn_free_page` will make the page available for allocations again.
We still have work to do on the infrastructure, but we
are very nearly ready to start implementing higher level concepts, like data structures. The next chapter will deal with issues such as allocating multiple
pages and managing pages metadata.

=== Unit tests

As usual, chapter close means that we need to unit test our code. 

[source,python]
.Listing 5.14 - Unit testing the transaction API
----
include::../pyapi/tests05.py[]
----
////