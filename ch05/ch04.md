
# Managing disk space allocations

In the previous chapter, we built up the transaction API and were able to modify a page and persist it back. At this point, the code we have makes absolutely no 
assumptions about the data we have on disk. We operate on the data in page units and blindly. This cannot go on, because we can't expect the users to know how to 
manage the pages and their content by themselves.
We need to be able to allocate and free pages. Once we have that, we can build more sophisticated data structures. 

The API we want to have are:

* `MUST_CHECK bool allocate_page(txn_t tx, page_t* page);`
* `MUST_CHECK bool free_page(txn_t* tx, page_t* page);`

Let consider what we actually need to do in order to implement this functionality. We need to persist somewhere that pages are taken or free. We need to be able
to search for a free page and we need to be able to mark a page as free. That means that we are going to store that information in the file itself. And that lead
to a bunch of questions. How are we going to do this? What would be the format of the data? How well will it play with future features?

We want to create a system that will serve for the foreseeable future, we want to ensure that it plays nicely with the API we created so far and that is doesn't
require complex implementation. We are too low in the stack yet to be able to do truly interesting things. The whole point of this book is to build the features
one on top of the other. 

## The file header

Looking at the API above and how we can implement them, I think we'll the following information:

* The size of the file in pages - we need to store that information inside the data file because relying on the size of the file as reported by the operating
  system cannot serve us for long. If we failed after the file size was extended but didn't update our internal metadata, we'll probably not enjoy the result.
* A way to tell if a page is free or in used.

Right now we need to keep track of only one piece of data about the file, its size in pages, but I'm sure that we'll have more in the future. To handle that
we'll create the following structure to serve as the header for the file and be the metadata location. You can see how the first version looks like in 
Listing 4.1.

```{caption="The file header structure contains metadata about the file" .c}
#define FILE_HEADER_MAGIC \
	(9410039042695495) // = 'Gavran!\0'

typedef struct file_header {
    uint64_t magic;
    uint64_t number_of_pages;
    uint32_t version;
    uint32_t page_size;
} file_header_t;

typedef struct database_options{
    uint64_t minimum_size;
} database_options_t;

typedef struct database_state db_state_t;

typedef struct database {
    db_state_t* state;
} database_t;


MUST_CHECK bool open_database(const char* path, database_options_t* options);
MUST_CHECK bool close_database(database_t* db);
```

The header in Listing 4.1 has a magic field, which must be set to the `FILE_HEADER_MAGIC` value. This is how we'll test if a file is a valid Gavran file or
something else. We already spoke about the `number_of_pages` and why we need it and the `version` field is future proofing. If we'll need to modify the 
layout of the data on disk, we can detect it from the header and react to it. The `page_size` is used to verify that we aren't attempting to open a file
whose page size is different from the `PAGE_SIZE` we are expecting.

The next question to ask is where are we going to place this information. The obvious answer is in the header, no? It is right there in the name. Let's see
what needs to be done to add this to our code. We need a higher level abstraction than the file, we need to now operate at the _database_ level, instead.
This is why we have the `database_options_t` and the `open_database` function. We are using the same `state` pointer trick as we did in the previous chapter, 
to allow us more freedom with how we are managing the internal state of our storage engine. 

In Listing 4.2, you can see what are the interesting details that we want to keep around as our state at the database level.

```{caption="The database state structure holds everything we need about a database" .c}
struct database_state{
    database_options_t options;
    file_header_t header;
    void* address;
    uint64_t address_size;
    file_handle_t* handle;
};
```

The `options` is fairly obvious. Right now we don't really have many options, but we will add to them and it make sense to store them where they are reachable.
The `header` we keep because we are going to need that quite often as we build the rest of our storage engine. The `address` is the `mmap`ed memory from the
file and the `address_size` is the size of the mapping. The `handle` data is stored immediately after the database state (and the filename past that) and we
can allocate the whole thing in one call. 

Before we get to actually opening the database, I want to look at how we'll _close_ it. The workhorse of Listing 4.3 is the `close_database_state` function.
This is called from `close_database` as well as `close_database_state_p` and takes care of tearing down the database we created properly. 
Why do we have dual entry points into closing down the database? The caller is expected to call `close_database` and we call `close_database_state_p` from 
a `defer` to handle failures in creating the database.

```{caption={Closing the database properly, accounting for partial construction} .c }
static MUST_CHECK bool close_database_state(db_state_t* state){
    if(!state)
        return true; // double close?
    bool result = true;
    if(state->address){
        if(unmap_file(state->address, state->address_size)){
            mark_error();
            result = false;
        }
    }
    if(state->handle){
        if(!close_file(state->handle)){
            mark_error();
            result = false;
        }
    }
    free(state);
    return result;
}

static void close_database_state_p(void* p){
    if(!close_database_state(p)){
        mark_error();
    }
}

bool close_database(database_t* db){
    if(!db->state)
        return true;// double close?
    bool result = close_database_state(db->state);
    db->state = 0;
    return result;
}
```

The first time that I wrote the `open_database` function, the amount of error handling was atrocious. We are coordinating resources around:

* Memory
* File
* Disk space allocation
* Memory mapped file
* Validation of the file format

Each one of them can fail and then we have to do the appropriate cleanup. I refactored said error handling into a `goto` based solution, but 
I still didn't like it. Then I realized that I can use the `defer` option to do the cleanup. Let's look at Listing 4.4 and see how that 
is done.

```{caption="Opening the database" .c}
static MUST_CHECK bool validate_options(
		database_options_t* options){

    if(options->minimum_size)
        option->minimum_size = 128*1024;

    if(option->minimum_size < 128*1024){
        push_error(EINVAL, 
        	"The minimum_size cannot be less than %d", 
        	128*1024)
        return false;
    }
        
    if(option->minimum_size % PAGE_SIZE) { 
        push_error(EINVAL, 
        		"The minimum size must be page aligned (%d)",
        		 PAGE_SIZE);
        return false;
    }

    return true;
}

bool open_database(const char* path, database_options_t* options, database_t* db){

    db_state_t* ptr = 0;
    // defer is called on the _pointer_ of
    // ptr, not its value;
    size_t* cancel;
    try_defer(close_database_state_p, &ptr, cancel);

    if(!validate_options(options)){
        mark_error();
        return false;
    }

    size_t db_state_size;
    if(!get_file_handle_size(path, &db_state_size)){
        mark_error();
        return false;
    }
    db_state_size += sizeof(db_state_t);

    ptr = calloc(1, db_state_size);
    if(!ptr){
        push_error(ENOMEM, 
            "Unable to allocate "
            "database state struct: %s", path);
        return false;
    }
    ptr->handle = (file_handle_t*)(ptr+1);

    if(!create_file(path, ptr->handle)){
        push_error(EIO, "Unable to create file for %s", path);
        return false;// cleanup via defer
    }

    ptr->options = *options;
    if(!ensure_file_minimum_size(ptr->handle,   
            options->minimum_size)){
        mark_error();
        return false;// cleanup via defer
    }
    if(!get_file_size(ptr->handle, &ptr->address_size)){
        mark_error();
        return false;// cleanup via defer
    }

    if(!map_file(ptr->handle, 0, 
            ptr->address_size, &ptr->address)){
       mark_error();
       return false;// cleanup via defer
    }
    
    if(!handle_newly_opened_database(ptr)){
        mark_error();
        return false;// cleanup via defer
    }

    db->state = ptr;
    *cancel = 1;// ensuring that defer won't clean it
    return true;
}

```

We first validate the passed `options`, then we start setting up the database. Creating the file, ensuring file size, mapping the memory, etc.
Each one of these actions may fail and require cleanup. I have used the `defer` macro previous to handle this situation, but now we have a 
different scenario. 

I don't want to unconditionally release those resources, I want to do that if the function was not successful. It it was successful, then I 
want no cleanup and to serve it to the caller. To handle that scenario, I defined a `try_defer` macro, which allows me to cancel the deferral
if needed. As you can see, we get a `cancelled` pointer that we can set to `1` in order to cancel the deferal. That allows me to have my 
cake in the sense that I don't have to use `goto` or write complex error handling code and still be able to cancel said behavior as needed.
Listing 4.5 shows the implemetnation of `try_defer`. 

```{caption="Setting a cancellable defer option allows for better error handling" .c}
struct cancel_defer {
   void* target;
   void(*action)(void*);
   size_t cancelled;
};

void _try_defer(struct cancel_defer* cd);

#define try_defer(func, var, cancelled_ptr) struct cancel_defer  \
   CONCAT(__defer__, __LINE__) __attribute__ \
   ((__cleanup__(_try_defer))) = {var, func, 0}; \
   cancelled_ptr = & CONCAT(__defer__, __LINE__).cancelled

void _try_defer(struct cancel_defer* cd) {
   if(cd->cancelled)
      return;
   cd->action(cd->target);
}
```

The was `try_defer` works in Listing 4.5 is similar to `defer`, relying on the `cleanup` property. However, instead of relying on the compiler
to call the function we route the call through the `_try_defer` function first. Where we are testing if the the user set the cancelled flag 
and we need to avoid calling the specified cleanup action.

After all this work, we can now open a database using the code in Listing 4.6. I think you'll agree that this is much nicer API to present to
our users. 

```{caption="Opening a database using the new API" .c}
database_options_t options = {0};
database_t db;
if(!open_database("db/orev", &options, &db)){
  print_all_errors();
  return EIO;
}

```

The `open_database` function in Listing 4.5 contains a new function that we didn't cover: `handle_newly_opened_database`. All the work that was
done in `open_database` was just setup. Opening the file, getting the memory map, etc. We _still_ haven't done anything to the file and we 
still have no header.

Listing 4.7 fix all those issues and show how our storage engine opens a file. 

```{caption="Starting up a database by reading the metadata or setting it up" .c}
static MUST_CHECK bool handle_newly_opened_database(database_t* db){

    db_state_t* state = db->state;
    file_header_t* header1 = state->address;
    file_header_t* header2 = 
    	(void*)((char*)state->address + PAGE_SIZE/2);
    
    // at this point state->header is zeroed
    // if both headers are zeroed, we are probably 
    // dealing with a new database
    bool isNew = 
    	!memcmp(header1, &state->header, sizeof(file_header_t)) && 
        !memcmp(header2, &state->header, sizeof(file_header_t));

    if(isNew) {
        // now needs to set it up
        state->header.magic = FILE_HEADER_MAGIC;
        state->header.version = 1;
        state->header.page_size = PAGE_SIZE;
        state->header.number_of_pages = 
        	state->address_size / PAGE_SIZE;
        if(!set_file_headers(state)){
            mark_error();
            return false;
        }
    }
    file_header_t* selected = 
    	header1->magic != FILE_HEADER_MAGIC ? 
    		header2: header1;
    if (selected->magic != FILE_HEADER_MAGIC) {
        push_error(EINVAL, 
        		"Unable to find matching header in"
        		" first page of %s", 
        		get_file_name(state->handle));
        return false;
    }
    if(selected->number_of_pages * PAGE_SIZE > 
    		state->address_size){
        push_error(EINVAL, 
        	"The size of the file %s is %lu but"
        	" expected to have %lu pages, file "
        	"was probably truncated", 
            get_file_name(state->handle), 
            state->address_size, 
            selected->number_of_pages * PAGE_SIZE);
        return false;
    }
    if(selected->page_size != PAGE_SIZE){
        push_error(EINVAL, 
        	"File %s page size is %d, expected %d", 
            get_file_name(state->handle), 
            selected->page_size,
            PAGE_SIZE );
        return false;
    }

    return true;
}
```

The first thing we do in `handle_newly_opened_database` is to get the first page of the file and look at two locations in it. You can look at Figure 4.1 
to see a diagram of how the data is expected to be laid on on the file. The idea is that in the first page, we are going to store the header _twice_, 
once at the start of the file (position 0) and once at the midway of the page (position 4096). 

![Physical layout of the header records in the first page](./ch04/img01.png)

Why are we storing the header data twice? Note that we are spreading the data 4KB apart, which is the size of a block. The idea is that we are going to 
have a backup copy of the file header if we had an incomplete write or a failure. This is just the first of _many_ preventive steps that we are going to 
take. 

Because we test both locations, we will determine if the file is new if the first page is full of zeroes. A newly allocated file is always going to be filled
with zeroes, so we need to setup the file header for the first time and write it back to disk. Listing 4.8 has the deatils on how that is done.

If the file isn't new, we select one of the headers and test it. We check that the file has the right version and page size that we expect as well as
well as the right first 8 bytes signature. If all validation pass, we are good to go.

```{caption="Updating the file header" .c}
static MUST_CHECK bool set_file_headers(database_t * db){
    txn_t tx;
    if(!create_transaction(db, 0, &tx)){
        push_error(EINVAL, "Failed to create a transaction"
        	" on database init: %s", 
        	get_file_name(db->state->handle));
        return false;
    }
    defer(close_transaction_p, &tx);
    page_t page = {0, 0};
    if(!modify_page(&tx, &page)){
        push_error(EINVAL, "Unable to get first"
        	" page of file: %s", 
        	get_file_name(db->state->handle));
        return false;
    }
    memcpy(page.address, 
    		&db->state->header, sizeof(file_header_t));
    memcpy((char*)page.address + PAGE_SIZE/2, 
    		&db->state->header, sizeof(file_header_t));

    if(!commit_transaction(&tx)){
        push_error(EINVAL, 
        	"Unable to commit init transaction on: %s",
        	get_file_name(db->state->handle));
        return false;
    }

    return true;
}
```

Listing 4.8 is the first time that _we_ are actually starting to use our own API to implement real functionality. As part of starting up the database
we'll create a transaction, modify the first page so we can write the headers and commit to the file. 

## Managing free pages

Now that we have all of this setup properly, the question _why_ raises itself. We wanted to implement `free_page` and `allocate_page`, how does this 
help us? The answer is that in order to write those functions, we need to have a place to store metadata about the file. We now have a place to do this
setup: `handle_newly_opened_database` and a method to do that, using our transaction API.

The next step is deciding exactly how we'll implement the free list. I want to build up in complexity, so any complex data structure is going to be hard
to build. The easiest way to manage the free space is to use a bitmap or a bit array for the free/in used marker.

Let's run some numbers and see how feasible this is? Let's assume we have a file that is 512GB in size, using 8KB pages, that gives us 
`67,108,864` pages to keep track of. In order to manage that using a bitmap, you'll `8,388,608` bytes which is exactly 8MB. In other words using a bitmap
to store the free/busy mode means that we will use 1/65,536 of the data for the free list. That means that about 0.0015% of the disk space will be dedicated for
this purpose.

The bitmap approach has several advantages:

* Simple to implement and obvious how to get working.
* Negligble amount of space overhead.
* There are many ways to efficeintly search a bitmap.
* There is a fixed size for the free list, we don't need to handle alloc / decalloc of space except when we grow the actual file.

This hits all the sweat spots, so let consider how we can go about implementing this? If you'll recall Figure 4.1, we are using the first page of the file 
as the location of the headers. Where would we put the free space bitmap?

As easy solution would be to place it as the second page, but that has an issue, how are we going to handle growing the file? A single page will give us
enough bits to manage a free list of a file up to 512MB. But what would you do next? You would need more space and it is best if we kept the free list
bitmap as a single consecutive buffer. 

The answer is that we are going to manage this process _using_ the free list itself. One of the responsabilities of the `handle_newly_opened_database`
will be to setup the initial free list bitmap. Following this, when we need to increase the free list size, we'll ask the free list itself where we
can place the increased list size and then free the old location.

Simple, at least as a concept. Let's see what will happen when we sit down to actually implement this...

We'll actually go about this the other way around, first, we'll setup the database properly, then we'll write the code that uses it.
The first thing I did was rename `set_file_headers` to `initialize_file_structure`, since we are going to be doing more work there. I've added the 
code in Listing 4.9 immediately after creating the transaction.

```{caption="Setting up free space bitmap for future calls" .c}
db->state->header.free_space_bitmap_start = 1;
db->state->header.free_space_bitmap_in_pages =
    get_number_of_free_space_bitmap(db->state);

page_t page_bitmap = {1, 0};
if (!modify_page(&tx, &page_bitmap))
{
  push_error(EINVAL,
              "Unable to setup free space bitmap for %s",
              get_file_name(db->state->handle));
  return false;
}
uint64_t busy_pages = db->state->header.free_space_bitmap_in_pages + 1;
if (busy_pages > BITS_IN_PAGE)
{
  // TODO: handle initial file allocation that is greater than 32TB
  push_error(ENOMEM,
              "Free space bitmap metadata cannot exceed %d entries",
              BITS_IN_PAGE);
  return false;
}
for (size_t i = 0; i < busy_pages; i++)
{
  set_bit(page_bitmap.address, i);
}
}
```

There are a few unfamiliar functions here, which are shown in Listing 4.10, but they should be clear from context. What we are doing is computing
how many pages will need for the free space bitmap, then checking how many pages of bits we'll need to fill in the free space bitmap itself. We 
store that value in a new field `free_space_bitmap_in_pages` inside the file header. That is going to be very heavily used, and the size of the 
file may not be a good indication of the used pages during certain operations (expanding the database file, preallocating free space size, etc), 
so keeping that explicitly helps. For the same reason `free_space_bitmap_start` is kept so we'll know where to find the free space mapping if we 
need to move it.

What we are doing here is setting the busy mark on the first page (the header) as well as the subsequent pages that we reserve for the free list. By 
using the free list itself to manage that we are able to significantly cut down on the complexity of the system. LMDB, for example, uses it own
data structure (B+Tree) to manage the free list. That can lead to recursion where the free list needs to allocate or free a page while a free 
list operation is ongoing. That can lead to... issues and took a while to properly stabilize. This model, however, solve all those issues very
neatly.

> **Preparing for Biggest Data**
>
> I'll admit that the code is vastly over prepared. It is ready to handle a scenario where we need to mark _more_ than a full page of bits 
> (65,536) of them just for the free space bitmap. Each one of those pages is 8Kb in size, so that means that the _free space bitmap_ is going 
> to be larger than 512MB.
>
> Each bit in the bitmap tracks an 8Kb page. So that gives us a total of `4,294,967,296` 8Kb pages or a data file that is 32TB in size. 
> I consider it unlikely that you'll create a file that large to start with, so we'll ignore that. Fixing it isn't hard, but it is awkward
> with our current API, it will become much better soon, and then we'll fix this. 

Let's look at the utility functions that we defined before looking into what is actually getting persisted. The new functions are shown in Listing 4.10.

```{caption="New functions to help build the free space bitmap" .c}
#define BITS_IN_PAGE (PAGE_SIZE * 8)
static inline uint64_t 
    get_number_of_free_space_bitmap(db_state_t *db)
{
  return db->header.number_of_pages / BITS_IN_PAGE +
         (db->header.number_of_pages % BITS_IN_PAGE ? 1 : 0);
}

static inline void set_bit(uint64_t *buffer, uint64_t pos)
{
  buffer[pos / 64] |= (1UL << pos % 64);
}

static inline void clear_bit(uint64_t *buffer, uint64_t pos)
{
  buffer[pos / 64] ^= ~(1UL << pos % 64);
}
```

As you can see, there really isn't much here to talk about. I'm including these function for completion sake. 

Another thing to note is that because we rely on the transaction and `modify_page`, our changes are automatically persisted when the transaction is
committed. We are starting to see the benefits of our infrastructure!

You can look at Figure 4.2 to see how the memory it laid out after the `initialize_file_structure` function has run.

![Physical layout of the file after initialization, with the free list bitmap set to reflect busy pages](./ch04/img02.png)

As you can see in Figure 4.2, the second page is used for the free list and the first two bits there are marked as busy. The rest of the page is 
filled with zeros, indicating free pages. Where did those zeros come from, however? We didn't set them up.
These zeros are there because we create a new file. Even though we preallocated the size of the file, the operating system ensures that the 
contents of the file are zeroed. Otherwise, you may get sensitive data from other files. We rely on this property here to avoid doing extra work.

> **Desiging for the underlying system**
>
> We haven't touched on this much yet, but one of the core design principles that I keep in mind while build Gavran is that I want to work _with_
> the systems I'm using. That means understanding how hardware, processors, memory and operating systems are built and what patterns they seek
> to optimize.
>
> If we intentionally build Gavran to have patterns that the underlying software and hardware is already setup to speed up, we are going to get
> amazing benefits, with very little apparent work. A lot of thought has gone inot how to structure things so you don't _need_ to write a lot
> of code to get the desired functionality.

## Freeing a page

The act of freeing a page is a lot easier than allocating one using this model. That is typically _not_ the case, so this feature of the system
architecture makes me very happy. Let's look at Listing 4.11 to see how this is done.

```{caption="Freeing a page by zeroing it and clearing its busy bit" .c}
bool free_page(txn_t *tx, page_t *page)
{
  if (!modify_page(tx, page))
  {
    push_error(EINVAL,
       "Unable to get page so we could free it for: %lu",
       page->page_num);
    return false;
  }

  memset(page->address, 0, PAGE_SIZE);

  page_t free_space_page = {page->page_num / BITS_IN_PAGE, 0};
  if (!modify_page(tx, &free_space_page))
  {
    push_error(EINVAL,
       "Unable to modify free space page %lu"
       " so we could free page: %lu",
       free_space_page.page_num,
       page->page_num);
    return false;
  }

  clear_bit(free_space_page.address, 
        page->page_num % BITS_IN_PAGE);

  return true;
}
```

The `free_page` in Listing 4.11 is getting the page that we want to free and zero it as its first action. I'm doing that for the following reasons:

* Ensure that if you try to access a page that was freed, you'll know about it straight away.
* Scrub away the data the user indicated the they want to delete^[This isn't really a security feature, mind. You'll usually work at a level
  smaller than a page anyway.].
* Zero page optimization in the operating system^[https://devblogs.microsoft.com/oldnewthing/20161109-00/?p=94675].

Note that aside from zeroing the page, we don't do anything special with it. Given that we set it in the free space bitmap, it may be used again if
the transaction will allocate a new page. The only thing that matters is that the page is modified and will be written to disk. The changes to 
the free space bitmap are also on a modified page that will be written to disk. So we don't actually _need_ to do anything special here.

## Building an allocation strategy

Memory allocation (and this is what the `allocate_page` is all about) is a complex topic. There have been papers, books and dissertations written about
the topic. The oldest refernce that I could find for a memory allocation algorithm is from _1963_. The latest I could find was this week, I'm pretty sure
that if you flex your Google musles, you'll be able to find one posted today. For whatever value of today you feel like choosing.

There are _conferences_ about memory management^[https://conf.researchr.org/track/ismm-2020/ismm-2020]. Just memory management. 
I'll let that sink in for a while, because we have been doing that for over half a century and this is still a hot area of research. 
I'm not going to try to win prizes with the allocation strategy I'm going to outline here, but at the same time, the _reason_ that this is such a hot topic
is that this is a critical piece of functionality. 

A good allocator should be fast to execute, of course, but it also has a host of other properties that we need to consider. Among them we have:

* Increase locality of reference. Having related data sit physically close can be a major performance boost.
* Reduce fragmenetation. Right now, we only request a single page at a time, so that is no issue. We need to be prepared for when we'll need to deal with
  multi page allocations. In that case, we want to avoid internal fragmentation as much as possible.

We already know that the backing store of the allocation is the free space bitmap. A busy page is marked with 1 and a free with 0. In eseence, the allocator
needs to be able to find the position of a zero bit in the bitmap. The good news is that this is very cheap operation, usually. The bad news is that we need
to be able to answer the question not on a single bit but on a range as well.

The basis for my code is from Daniel Lemire's work^[https://lemire.me/blog/2018/02/21/iterating-over-set-bits-quickly/], adapted to allow us to find a range
of values. We start from the function declaration in Listing 4.12.

```{caption="Entry point to searching a cleared range in the bitmap" .c}
bool find_free_range_in_bitmap(
    uint64_t *bitmap, size_t bitmap_size,
    size_t size_required, size_t near_pos,
    size_t *bit_pos);
```

This function accepts the bitmap buffer and its size, the required size and the preferred location and returns the found position using the `bit_pos` output
value. As usual, we use the return value to indicate success or failure only. In this case, the function does no allocation and a failure here means that we
couldn't find a free range to satisfy the required space.

Listing 4.13 shows how that function works. There are quite a few of moving pieces here, but that piece of code went through several iterations of refactoring
and ended up being quite nice in the end.

```{caption="Implementing search for a free range in the bitmap" .c}
struct selected_range
{
    size_t position;
    size_t size_available;
};

struct range_finder
{
    // input
    uint64_t *bitmap;
    size_t bitmap_size;
    size_t size_required;
    size_t index;

    // output
    struct selected_range selection;

    // the current word we are working on
    uint64_t current;

    // state
    uint64_t current_set_bit;
    uint64_t previous_set_bit;
};

static void init_range(
    uint64_t *bitmap, size_t bitmap_size,
   size_t size_required,
   struct range_finder *restrict range)
{
    range->bitmap = bitmap;
    range->bitmap_size = bitmap_size;
    range->size_required = size_required;
    range->current = bitmap[0];
    range->previous_set_bit = ULONG_MAX;
    range->index = 0;
}

bool find_free_range_in_bitmap(
    uint64_t *bitmap, size_t bitmap_size,
   size_t size_required, size_t near_pos,
   size_t *bit_pos)
{
    if (!size_required || near_pos / 64 >= bitmap_size)
        return false;

    size_t high = near_pos / 64;

    struct range_finder range;
    init_range(bitmap + high, bitmap_size - high, 
            size_required, &range);

    if (find_smallest_nearby_range(&range, high != 0))
    {
        *bit_pos = range.selection.position + high * 64;
        return true;
    }
    if (!high)
    {
        return false; // already scanned it all
    }

    // we search _high_, couldn't find anything, try lower?
    init_range(bitmap, high, size_required, &range);
    if (find_next_range(&range))
    {
        *bit_pos = range.selection.position;
        return true;
    }

    return false;
}
```

We start the code in Listing 4.13 by defining a few structs to hold our state. The process of searching fpr a free range is fairly involed and by explicitly
managing our state via a struct we end up with clearer code. The `init_range` is also trivial. The implementation of `find_free_range_in_bitmap` consider the
bitmap as an array of `uint64_t`, this means that we are able to process the bitmap with 64 bits at a time, instead of 8 bits if we were using `char` array.

> **Important: This function is pure**
>
> The `find_free_range_in_bitmap` is a pure function. In other words, it does _not_ modify its input or make any change to the system. After finding
> the right range, the responsbility to mark is as busy is on the caller.

The first thing we do is to search in the bitmap _after_ the `near_pos` location. The way we do that, we find the array index inside the `uint64_t` bitmap
and start the search from it. Note that it is possible to find a value _earlier_ than the `near_pos` value, if it is located on the same word (within 64
pages). In other words, when requesting a page from the function, we have a high liklihood that it will be placed within 512Kb of the requested location
if there is room for that.

If we can't find a value after the `near_pos` value, we'll then try looking the other way around, from the beginning of the bitmap to the `near_pos` and
see if there is anything here that matches. Note that for this query, I'm asking for _any_ range, while before I asked for the best range. 

Figure 4.3 shows a bitmap in a visual manner for the bitmap: `{0x80520A27102E21, 0xE0000E00020, 0x1A40027F025802C8, 0xEE6ACAE56C6C3DCC}`. 

![A visual representation of the free space bitmap.](./ch04/img03.png)

Figure 4.3 has three types of cells:

* Marked with `X` - busy. 
* Marked with `V` and colored - we'll run a few sample queries on them, so I highlighted them for ease of identification.
* Empty - free cells. 

Look at the first row of cells in Figure 4.3, if we want to allocate a page near the marked position (red), where would you put it? What if we wanted to 
allocate two pages? In the middle of the image, there is another marked position (yellow), I want to get 4 pages near that location. And we want to get
7 pages near the last marked position (green). 

Let start from the basics, how can we find a range? This is done by the imaginatively named function: `find_next_range`. The API here uses the 
`init_range` and `find_next_range` system, this allow us to _iterate_ over the free ranges in the free list. That can be very useful if you need
to do something like display a fragmentation report. Listing 4.14 shows the code for this function.

```{caption="Finding the next range of cleared bits" .c}
static bool find_next_range(struct range_finder *restrict range)
{
 do
 {
   if (find_range_once(range))
   {
     if (range->current_set_bit % 64)
     {
         // mask the already found item
         uint64_t mask = 
             ~(ULONG_MAX << (range->current_set_bit % 64));
         range->current |= mask;
     }
     else
     {
         // run out in the current word, but maybe we
         // have more in the next?
         if (range->index + 1 < range->bitmap_size)
         {
             range->index++;
             range->current = range->bitmap[range->index];
             continue;
         }
         else
         {
             range->current = ULONG_MAX;
         }
     }
     return true;
   }
   range->index++;
   if (range->index >= range->bitmap_size)
       return false;
   range->current = range->bitmap[range->index];
 } while (true);
}
```

The code in Listing 4.14 shows that the bulk of the work is done elsewhere, in `find_range_once`. That method operates on a single `uint64_t` value while 
`find_next_range` is operating over the entire bitmap. You can see that once we found a range, we'll mask it so we'll _not_ see it the next time. That is
the core of how we are able to iterate over the free ranges in the bitmap. We also need to handle running out of bits in the current value and merging 
with the next one. 

This function is _eager_, that is, if we asked for a range of 1 page and an available range of 3 pages was found, it will return that range. The first range
that match the required size will be returned, in other words. This is called the first fit allocation strategy and just for fun, here are couple of papers 
from 1974 that discusses its usefulness^[https://dl.acm.org/doi/pdf/10.1145/359436.359453 and 
https://www.researchgate.net/publication/220459885_Worst_Case_Fragmentation_of_First_Fit_and_Best_Fit_Storage_Allocation_Strategies]. They are mostly here
as a historical interest, they are testing this out on a PDP-11.

Listing 4.15 shows what is going on inside of `find_range_once`, which searching inside a single `uint64_t` is done.

```{caption="Searching for range (or partial range) inside a single word" .c}
static bool handle_zero_word(struct range_finder *restrict range)
{
    range->current_set_bit = (range->index + 1) * 64;
    if (range->current_set_bit > 
        range->previous_set_bit + range->size_required)
    {
        range->selection.position =
            // intentionally overflowing here
            range->previous_set_bit + 1; 
        range->selection.size_available =
            (range->current_set_bit - range->selection.position);
        return true;
    }
    return false;
}

static bool find_range_once(struct range_finder *restrict range)
{
  uint64_t bitset = range->current;

  if (bitset == ULONG_MAX)
  {
    // all bits are set, can skip whole thing
    range->previous_set_bit = (range->index + 1) * 64 - 1;
    return false;
  }

  if (bitset == 0)
  {
    return handle_zero_word(range);
  }

  while (bitset != 0)
  {
     int r = __builtin_ctzl(bitset);
     range->current_set_bit = (range->index) * 64 + (uint64_t)r;
     if (range->current_set_bit >
         range->previous_set_bit + range->size_required)
     {
         // intentionally overflowing here
         range->selection.position = range->previous_set_bit + 1;
         range->selection.size_available =
             (range->current_set_bit - range->selection.position);
         range->previous_set_bit = range->current_set_bit;
         return true;
     }
     range->previous_set_bit = range->current_set_bit;
     bitset ^= (bitset & -bitset);
  }

  return handle_zero_word(range);
}

```

The `find_range_once` starts by checking if the current word is either all full or all empty. If it is full, we record that in the `range` state and return.
The caller is responsible for calling us again with the next word. Note that what make this code challanging is that we are keeping track of the state 
_across_ calls. For example, we may have a free range that strides a word boundary. That will be handle in _two_ calls to `find_range_once`. 

We use the `range->current` to store the current word that we operate on and we copy it from the array whenever we start processing a value. The reason we
do it in this manner is that `range->current` is _mutable_. After each call to `find_range_once`, we'll mark the areas that we already seen and call it 
again to find the next range. We don't want to be modifying the bitmap in this function, since that would mark pages as busy and the 
`find_free_range_in_bitmap` is a pure function.

If the `bitset` is not either empty or full, we have to find how big a range we have inside this value. We measure this using `__builtin_ctzl` which is 
an operation that would count the trailing zeros on the value. We use that to compute the distance to the first set bit, check whatever that gives us 
the right range or not. If we didn't find the right range, we then clear the least significant bit using: `(x & -x)`. This will keep just the least 
significant bit in the number, and we then clear that from the current value. 
That allows us to count the distance to the set bit and then remove that set bit and count again.

Finally, we call `handle_zero_word` in one of two cases. If the entire word is zeroed or if we run through all the set bits and now we have a free range at the
end of the value.  We rely on `previous_set_bit` to be set to `ULONG_MAX` by `init_range` and then add one to it. If there have been no other set bits, 
the value overflow and is set to 0, which is then used as the starting point of the current range. If there is a value in `previous_set_bit`, we move one
past the filled bit and return that. This code is succint, and I like how it turned out.

The core issue with first fit is that it can cause internal fragmentation. In other words, we allocate pages in such a pattern that even though we have the
the right number of pages free, we don't have enough _consecutive_ pages to answer the allocation. 

> **Why are we spending so much time with the allocator?**
>
> It may seems strange that I'm covering so much time right now for the implementation of the allocator. I just checked how it goes with Voron, RavenDB's storage
> engine, and I found that the last time anyone made a meaningful change there was in Oct of 2015 and most of the actual work was done in 2013. It has been
> able to handle production loads for all this time without us really needing to pay it much attention.
>
> However, it took _time_ and a lot of hard work to get there. In Gavran, I'm trying to avoid that complexity pitfall by doing things properly from the get go.
> I'm writing this in Jun of 2020, which means that five to eight years after the fact, I still remember how hard getting free space handling in Voron was to
> get _right_.

In Listing 4.13, you can see that `find_free_range_in_bitmap` doesn't call `find_next_range` immediately. That is because first fit _works_, but we want to 
see if we can do better. This is where the `find_smallest_nearby_range` come into play. You can see it in full in Listing 4.16. For such a short function 
there is a _lot_ of functionality there.

```{caption="Finding the best match range for the requested size" .c}
#define MAX_DISTANCE_TO_SEARCH_BEST_MATCH 64

static bool find_smallest_nearby_range(
        struct range_finder *restrict range, bool search_nearby)
{
    struct selected_range current = {0, SIZE_MAX};
    size_t boundary =
        MAX_DISTANCE_TO_SEARCH_BEST_MATCH +
        // the bigger the request range
        // the less we care about locality
        +range->size_required;

    while (find_next_range(range))
    {
        if (range->size_required ==
             range->selection.size_available)
            return true;
        if (current.size_available >
             range->selection.size_available)
        {
            current = range->selection;
        }
        if (search_nearby &&
             range->selection.position > boundary)
        {
            // We have gone too far? Stop being choosy
            if (current.size_available < 
                    range->selection.size_available)
            {
                range->selection = current;
            }
            return true;
        }
    }

    range->selection = current;
    return current.size_available != SIZE_MAX;
}
```

What `find_smallest_nearby_range` does is to use `find_next` in a loop, trying to find the best match. In this case, we define best as the smallest
range that can fit the requested size. However, we also take locality of reference into account here. The code will try to find a range that starts
within 64 pages (512Kb) from the requested position. If we can't find such a range, we'll try to either use a larger than necessary range from near
the requested location or the first suitable range of any size that we run into.

We call `find_smallest_nearby_range` from `find_free_range_in_bitmap` with range that starts at the current location. In other words, we are skipping
looking at the pages that come before the requested location. We'll look there only if we couldn't find a range afterward. This is important because
it bias the allocations forward.

That is an intentional design decision. The idea is that you'll call `find_free_range_in_bitmap` with the location of an item you already have and
ask it to be placed nearby. As you'll likely do that over a wide range of locations, that should balance things out. You can also pass `0` as the 
starting location, in which case we'll search for the _best_ fit in the entire bitmap, ignoring the location sensitive brake.

> **The allocator operates over a single bitmap**
>
> This allocator uses a single bitmap to find the ranges. As it current stangs, we deal with each page independently, so we have to scan them 
> individually. That means that if we have a request to allocate more than can be fit into a single page, we will fail. Right now, that means
> that we can't allocate more than 512MB in one shot. 
> 
> We'll fix this issue in a little bit, as well as the problem of the free space bitmap initialization.

## Allocating pages

Now that we have an allocator ready, let see what it takes to actually allocate a page, shall we? Without further ado, skip ahead to Listing 4.17.

```
bool allocate_page(txn_t *tx, page_t *page)
{
 file_header_t *header = &tx->state->db->header;
 uint64_t start = header->free_space_bitmap_start;
 uint64_t count = header->free_space_bitmap_in_pages;
 for (uint64_t i = 0; i < count; i++)
 {
   page_t bitmap_page = {i + start, 0};
   if (!get_page(tx, &bitmap_page))
   {
     push_error(EINVAL,
                "Unable to get page %lu",
                bitmap_page.page_num);
     return false;
   }
   size_t required_size = 1;
   size_t nearby = 0;
   size_t pos;
   if (find_free_range_in_bitmap(bitmap_page.address,
       PAGE_SIZE / sizeof(uint64_t), 
       required_size, nearby, &pos))
   {
     page->page_num = pos;
     if (!modify_page(tx, page))
     {
       push_error(EINVAL, "Unable to modify page %lu", pos);
       return false;
     }
     memset(page->address, 0, PAGE_SIZE);
     // now need to mark it as busy in the bitmap
     if (!modify_page(tx, &bitmap_page))
     {
       push_error(EINVAL, 
           "Unable to modify free space page %lu", pos);
       return false;
     }
     set_bit(bitmap_page.address, pos % BITS_IN_PAGE);
     return true;
   }
 }
 push_error(ENOSPC,
    "No more room left in the file %s to allocate %d",
    get_file_name(tx->state->db->handle), PAGE_SIZE);
 return false;
}
```

We are scanning through the free space bitmap, one page at a time, trying to find a free page. When we find the page, we call `modify_page` on it. We then
zero it. This isn't something that we _have_ to do, we already zero pages when we free them and we know that we are getting zeroed pages from the file 
system. I'm doing this to make doubly sure that we don't end up with strange things in here. The rule is that if you asked for a new page, you'll get it
free and clear.

Now, I need to mark the newly allocated page as busy. Note that I _cannot_ just use `bitmap_page` here, I got that through `get_page`, which returns a 
read only copy. I need to call `modify_page` on the page and then work with he _new_ address that we get. After that, it is just an issue of setting the
right bit and completing the operation successfully.

As it currently stand, the `allocate_page` will fail once we have run out of the internally allocated space. We'll need to address that, we want to allow
the user to increase the file size as needed. We'll deal with this issue in the next chapter.

## Putting it all together

This chapter has gone on longer than I expected, but we are finally here. You can look at Listing 4.18 to see how we can use the new API. I decided to skip
the error handling here, since this is just concept code. It makes the intent much more readable.

```{caption="Allocating and using the new API" .c}
database_t db;
database_options_t options = {0};
txn_t tx;
page_t page;

assert(open_database("db/orev", &options, &db));

assert(create_transaction(&db, 0, &tx));
assert(allocate_page(&tx, &page));

printf("New allocated page %lu\n", page.page_num);
strcpy(page.address, "Hello Gavran");

assert(commit_transaction(&tx));
assert(close_transaction(&tx));
assert(create_transaction(&db, 0, &tx));
assert(get_page(&tx, &page));

printf("%s\n", page.address);

assert(close_transaction(&tx));
assert(close_database(&db));
```

The code in Listing 4.18 will print the new allocated page number (2) and the string "Hello Gavran". We still have work to do on the infrastructure, but we
are very nearly ready to start implementing higher level concepts, like data structures. The next chapter will deal with issues such as allocating multiple
pages and how we can handle increasing the file size of the database dynamically.

